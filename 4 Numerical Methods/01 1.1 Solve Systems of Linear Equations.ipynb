{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f92922d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T04:06:17.486299Z",
     "iopub.status.busy": "2025-07-16T04:06:17.485936Z",
     "iopub.status.idle": "2025-07-16T04:06:17.535895Z",
     "shell.execute_reply": "2025-07-16T04:06:17.534508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 1.1 Solve Systems of Linear Equations\n",
       "\n",
       "[Study Notes](#study-notes)\n",
       "\n",
       "[Questions](#questions)\n",
       "\n",
       "\n",
       "\n",
       "### Key Points\n",
       "\n",
       "##### 1. üßÆ Systems of Linear Equations  \n",
       "- A system of linear equations can be written as $ Ax = b $, where $ A $ is the coefficient matrix, $ x $ is the vector of unknowns, and $ b $ is the constants vector.  \n",
       "- The system is **homogeneous** if all $ b_i = 0 $; otherwise, it is **non-homogeneous**.  \n",
       "- A system can have a **unique solution**, **infinitely many solutions**, or **no solution**.\n",
       "\n",
       "##### 2. üîÑ Elementary Operations and Equivalent Systems  \n",
       "- Elementary operations include:  \n",
       "  1. Interchanging two equations (or rows).  \n",
       "  2. Multiplying an equation (or row) by a non-zero constant.  \n",
       "  3. Replacing an equation (or row) by itself plus a multiple of another equation (or row).  \n",
       "- Two systems are **equivalent** if one can be obtained from the other by a finite number of elementary operations.  \n",
       "- Equivalent systems have the **same set of solutions**.\n",
       "\n",
       "##### 3. üî∫ Gaussian Elimination Method  \n",
       "- Gaussian elimination transforms the augmented matrix into an **upper triangular form** using elementary row operations.  \n",
       "- After forward elimination, the system is solved by **back substitution** starting from the last variable.  \n",
       "- The **pivot element** is the element used to eliminate variables below it in a column.\n",
       "\n",
       "##### 4. ‚ö†Ô∏è Pivoting and Numerical Stability  \n",
       "- If the pivot element is zero or very small, division by zero or large round-off errors can occur.  \n",
       "- **Partial pivoting** swaps rows to place the largest absolute value in the pivot position to avoid these issues.  \n",
       "- **Complete pivoting** swaps both rows and columns but is rarely used due to complexity.  \n",
       "- **Scaled partial pivoting** considers the relative size of elements in each row before swapping.\n",
       "\n",
       "##### 5. üìä Ill-Conditioned vs Well-Conditioned Systems  \n",
       "- A **well-conditioned** system‚Äôs solution changes little with small changes in coefficients or constants.  \n",
       "- An **ill-conditioned** system‚Äôs solution changes significantly with small changes, making it sensitive to round-off errors.  \n",
       "- The **condition number** measures how ill-conditioned a matrix is; a large condition number indicates ill-conditioning.\n",
       "\n",
       "##### 6. üìù Additional Key Points  \n",
       "- The augmented matrix $[A|b]$ combines the coefficient matrix and constants for easier manipulation.  \n",
       "- Elementary row operations have corresponding inverse operations, ensuring reversibility.  \n",
       "- Pivoting minimizes round-off errors and avoids division by zero during elimination.\n",
       "\n",
       "\n",
       "\n",
       "<br>\n",
       "\n",
       "## Study Notes\n",
       "\n",
       "### 1. üßÆ Introduction to Systems of Linear Equations\n",
       "\n",
       "A **system of linear equations** is a collection of one or more linear equations involving the same set of variables. For example, if you have variables $ x_1, x_2, \\ldots, x_n $, a system of $ m $ linear equations looks like this:\n",
       "\n",
       "$$\n",
       "\\begin{cases}\n",
       "a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n = b_1 \\\\\n",
       "a_{21}x_1 + a_{22}x_2 + \\cdots + a_{2n}x_n = b_2 \\\\\n",
       "\\vdots \\\\\n",
       "a_{m1}x_1 + a_{m2}x_2 + \\cdots + a_{mn}x_n = b_m\n",
       "\\end{cases}\n",
       "$$\n",
       "\n",
       "Here, the $ a_{ij} $ are coefficients (real numbers), and the $ b_i $ are constants on the right side of the equations.\n",
       "\n",
       "##### Key Concepts:\n",
       "- **Homogeneous system:** When all $ b_i = 0 $, the system is called *homogeneous*. It always has at least the trivial solution $ x = 0 $.\n",
       "- **Non-homogeneous system:** When at least one $ b_i \\neq 0 $, the system is *non-homogeneous*.\n",
       "- The system can be written compactly as $ Ax = b $, where:\n",
       "  - $ A $ is the **coefficient matrix** (contains all $ a_{ij} $),\n",
       "  - $ x $ is the vector of unknowns,\n",
       "  - $ b $ is the constants vector.\n",
       "- The **augmented matrix** $[A|b]$ combines the coefficient matrix and the constants for easier manipulation.\n",
       "\n",
       "##### Possible outcomes when solving $ Ax = b $:\n",
       "- **Unique solution:** Exactly one set of values for $ x $ satisfies all equations.\n",
       "- **Infinitely many solutions:** There are multiple solutions, often due to dependent equations.\n",
       "- **No solution:** The system is inconsistent (e.g., parallel lines that never intersect).\n",
       "\n",
       "\n",
       "### 2. üîÑ Elementary Operations and Equivalent Systems\n",
       "\n",
       "To solve systems of linear equations, we often manipulate the equations to simplify them. These manipulations are called **elementary operations** and are crucial because they do not change the solution set.\n",
       "\n",
       "##### The three elementary operations are:\n",
       "\n",
       "1. **Interchange two equations:** Swap the positions of two equations.\n",
       "2. **Multiply an equation by a non-zero constant:** Scale an entire equation by a constant $ c \\neq 0 $.\n",
       "3. **Replace an equation by itself plus a multiple of another equation:** For example, replace equation $ k $ by $ \\text{equation } k + c \\times \\text{equation } j $.\n",
       "\n",
       "These operations are reversible, meaning you can undo them by applying inverse operations.\n",
       "\n",
       "##### Why are these important?\n",
       "\n",
       "- Applying these operations transforms the system into an **equivalent system** ‚Äî one that has exactly the same solutions as the original.\n",
       "- This allows us to simplify the system step-by-step until it becomes easy to solve.\n",
       "\n",
       "##### Row operations on matrices:\n",
       "\n",
       "When working with matrices, these operations correspond to **elementary row operations**:\n",
       "\n",
       "- Swap two rows.\n",
       "- Multiply a row by a non-zero constant.\n",
       "- Add a multiple of one row to another row.\n",
       "\n",
       "Two matrices are **row-equivalent** if one can be obtained from the other by a finite sequence of these row operations.\n",
       "\n",
       "\n",
       "### 3. üî∫ Gaussian Elimination Method\n",
       "\n",
       "**Gaussian elimination** is a systematic procedure to solve linear systems by transforming the augmented matrix into an **upper triangular form** (all zeros below the main diagonal). Once in this form, the system can be solved easily by **back substitution**.\n",
       "\n",
       "##### How Gaussian elimination works:\n",
       "\n",
       "1. **Forward elimination:**\n",
       "   - Start with the first column and eliminate the variable $ x_1 $ from all rows below the first.\n",
       "   - Move to the second column and eliminate $ x_2 $ from all rows below the second.\n",
       "   - Continue this process until the matrix is in upper triangular form.\n",
       "\n",
       "2. **Back substitution:**\n",
       "   - Solve for the last variable $ x_n $ from the last equation.\n",
       "   - Substitute $ x_n $ into the second last equation to solve for $ x_{n-1} $.\n",
       "   - Continue substituting back until all variables are found.\n",
       "\n",
       "##### Important notes:\n",
       "\n",
       "- The **pivot element** is the element in the current row and column used to eliminate variables below it.\n",
       "- The process relies on the pivot element being non-zero to avoid division by zero.\n",
       "\n",
       "\n",
       "### 4. ‚ö†Ô∏è Pitfalls and Pivoting in Gaussian Elimination\n",
       "\n",
       "While Gaussian elimination is powerful, it has some challenges:\n",
       "\n",
       "##### Division by zero:\n",
       "\n",
       "- If the pivot element is zero, you cannot divide by it to eliminate variables.\n",
       "- This can happen if the matrix has zeros on the diagonal during elimination.\n",
       "\n",
       "##### Small pivot elements and round-off errors:\n",
       "\n",
       "- Even if the pivot is not zero but very small compared to other elements, numerical errors can become significant.\n",
       "- This can lead to inaccurate solutions due to **round-off errors** in computer calculations.\n",
       "\n",
       "##### Pivoting techniques to avoid these problems:\n",
       "\n",
       "- **Partial pivoting:** Before eliminating variables in a column, swap the current row with a row below that has the largest absolute value in that column. This ensures the pivot element is as large as possible, reducing round-off errors.\n",
       "- **Complete pivoting:** Swap both rows and columns to place the largest element in the pivot position. This is more complex and less commonly used because it changes the order of variables.\n",
       "- **Scaled partial pivoting:** Takes into account the relative size of elements in each row to decide which row to swap, improving stability.\n",
       "\n",
       "\n",
       "### 5. üìä Ill-Conditioned vs Well-Conditioned Systems\n",
       "\n",
       "When solving linear systems numerically, the **condition** of the coefficient matrix $ A $ is crucial.\n",
       "\n",
       "##### Well-conditioned system:\n",
       "\n",
       "- Small changes in the coefficients or constants lead to small changes in the solution.\n",
       "- These systems are stable and reliable to solve numerically.\n",
       "\n",
       "##### Ill-conditioned system:\n",
       "\n",
       "- Small changes in the coefficients or constants cause large changes in the solution.\n",
       "- These systems are sensitive to round-off errors and numerical instability.\n",
       "- The **condition number** of a matrix measures this sensitivity. A large condition number indicates ill-conditioning.\n",
       "\n",
       "##### Why does this matter?\n",
       "\n",
       "- Ill-conditioned systems are difficult to solve accurately using numerical methods.\n",
       "- Round-off errors, which are inevitable in computer calculations, can cause large errors in the solution.\n",
       "- When possible, avoid ill-conditioned systems or use specialized numerical techniques to handle them.\n",
       "\n",
       "\n",
       "### 6. üìù Summary and Practical Tips\n",
       "\n",
       "- Systems of linear equations can be solved using **direct methods** like Gaussian elimination or **iterative methods** (not covered here).\n",
       "- Use **elementary row operations** to simplify systems without changing their solutions.\n",
       "- Apply **Gaussian elimination** to reduce the system to upper triangular form, then solve by back substitution.\n",
       "- Always check for zero or small pivot elements to avoid division by zero or large numerical errors.\n",
       "- Use **pivoting** (especially partial pivoting) to improve numerical stability.\n",
       "- Be aware of the condition of your system; ill-conditioned systems require careful handling.\n",
       "- Understanding these concepts is essential for implementing reliable numerical algorithms for solving linear systems.\n",
       "\n",
       "\n",
       "\n",
       "<br>\n",
       "\n",
       "## Questions\n",
       "\n",
       "##### 1. Which of the following statements about a homogeneous system of linear equations are true?  \n",
       "A) It always has the trivial solution $ x = 0 $.  \n",
       "B) It can never have infinitely many solutions.  \n",
       "C) The system is written as $ Ax = 0 $.  \n",
       "D) It always has a unique solution.\n",
       "\n",
       "\n",
       "##### 2. Which of the following are elementary row operations?  \n",
       "A) Multiplying a row by zero.  \n",
       "B) Interchanging two rows.  \n",
       "C) Adding a multiple of one row to another row.  \n",
       "D) Multiplying a row by a non-zero constant.\n",
       "\n",
       "\n",
       "##### 3. Two linear systems are said to be equivalent if:  \n",
       "A) They have the same coefficient matrix.  \n",
       "B) One can be obtained from the other by a finite number of elementary operations.  \n",
       "C) They have the same augmented matrix.  \n",
       "D) They have the same set of solutions.\n",
       "\n",
       "\n",
       "##### 4. Which of the following are possible outcomes when solving a system $ Ax = b $?  \n",
       "A) No solution.  \n",
       "B) Exactly one solution.  \n",
       "C) Infinitely many solutions.  \n",
       "D) Solutions only if $ A $ is invertible.\n",
       "\n",
       "\n",
       "##### 5. In Gaussian elimination, the pivot element is:  \n",
       "A) The element used to eliminate variables in the rows below.  \n",
       "B) Always the largest element in the matrix.  \n",
       "C) The diagonal element in the current step.  \n",
       "D) The element that must never be zero during elimination.\n",
       "\n",
       "\n",
       "##### 6. What is the main purpose of partial pivoting in Gaussian elimination?  \n",
       "A) To avoid division by zero.  \n",
       "B) To reduce round-off errors.  \n",
       "C) To reorder the variables in the solution vector.  \n",
       "D) To ensure the pivot element is the largest in its column below the current row.\n",
       "\n",
       "\n",
       "##### 7. Which of the following statements about the augmented matrix $[A|b]$ are true?  \n",
       "A) It combines the coefficient matrix and the constants vector.  \n",
       "B) Elementary row operations on $[A|b]$ change the solution set.  \n",
       "C) It is used to perform Gaussian elimination.  \n",
       "D) It is always square.\n",
       "\n",
       "\n",
       "##### 8. Which of the following are true about ill-conditioned systems?  \n",
       "A) Small changes in coefficients cause large changes in solutions.  \n",
       "B) They are easy to solve numerically.  \n",
       "C) They have a large condition number.  \n",
       "D) Round-off errors can significantly affect the solution.\n",
       "\n",
       "\n",
       "##### 9. Which of the following are inverse operations of elementary row operations?  \n",
       "A) Interchanging the same two rows again.  \n",
       "B) Multiplying a row by zero.  \n",
       "C) Dividing a row by the same non-zero constant it was multiplied by.  \n",
       "D) Replacing a row by itself minus the same multiple of another row.\n",
       "\n",
       "\n",
       "##### 10. Which of the following are true about the back substitution step in Gaussian elimination?  \n",
       "A) It starts from the last equation and moves upward.  \n",
       "B) It requires the matrix to be in upper triangular form.  \n",
       "C) It can be performed before forward elimination.  \n",
       "D) It solves for variables one at a time.\n",
       "\n",
       "\n",
       "##### 11. Which of the following statements about the coefficient matrix $ A $ are correct?  \n",
       "A) It contains the constants on the right side of the equations.  \n",
       "B) It is always square.  \n",
       "C) It contains the coefficients $ a_{ij} $ of the variables.  \n",
       "D) Its invertibility guarantees a unique solution.\n",
       "\n",
       "\n",
       "##### 12. When is complete pivoting used, and what is its main drawback?  \n",
       "A) It swaps rows and columns to place the largest element as pivot.  \n",
       "B) It is rarely used because it changes the order of variables.  \n",
       "C) It guarantees no division by zero.  \n",
       "D) It is computationally simpler than partial pivoting.\n",
       "\n",
       "\n",
       "##### 13. Which of the following are true about the solution set of two equivalent linear systems?  \n",
       "A) They have exactly the same solutions.  \n",
       "B) One system can have more solutions than the other.  \n",
       "C) Elementary operations preserve the solution set.  \n",
       "D) The augmented matrices of equivalent systems are identical.\n",
       "\n",
       "\n",
       "##### 14. Which of the following can cause failure or inaccuracies in Gaussian elimination?  \n",
       "A) Pivot element being zero.  \n",
       "B) Pivot element being very small compared to other elements.  \n",
       "C) Using partial pivoting.  \n",
       "D) Round-off errors during elimination.\n",
       "\n",
       "\n",
       "##### 15. Scaled partial pivoting differs from partial pivoting because:  \n",
       "A) It considers the relative size of elements in each row.  \n",
       "B) It always swaps columns as well as rows.  \n",
       "C) It selects the pivot based on the largest absolute value divided by the largest element in the row.  \n",
       "D) It is used only for ill-conditioned systems.\n",
       "\n",
       "\n",
       "##### 16. Which of the following statements about the augmented matrix after forward elimination are true?  \n",
       "A) It is in upper triangular form.  \n",
       "B) It can be directly used to find the solution by back substitution.  \n",
       "C) It has zeros above the main diagonal.  \n",
       "D) It has zeros below the main diagonal.\n",
       "\n",
       "\n",
       "##### 17. Which of the following are true about the system $ Ax = 0 $?  \n",
       "A) It is always consistent.  \n",
       "B) It can have infinitely many solutions if $ A $ is singular.  \n",
       "C) It has no solution if $ A $ is invertible.  \n",
       "D) The trivial solution is always a solution.\n",
       "\n",
       "\n",
       "##### 18. Which of the following statements about row equivalence of matrices are correct?  \n",
       "A) Two matrices are row equivalent if one can be obtained from the other by elementary row operations.  \n",
       "B) Row equivalence implies the matrices have the same determinant.  \n",
       "C) Row equivalent matrices represent equivalent linear systems.  \n",
       "D) Row equivalence preserves the rank of the matrix.\n",
       "\n",
       "\n",
       "##### 19. Which of the following describe the effect of round-off errors in solving linear systems?  \n",
       "A) They can cause large errors in ill-conditioned systems.  \n",
       "B) They are negligible in all numerical methods.  \n",
       "C) They can be minimized by pivoting.  \n",
       "D) They do not affect the solution if the system is well-conditioned.\n",
       "\n",
       "\n",
       "##### 20. Which of the following are true about the method of solving the system by elementary operations?  \n",
       "A) It always leads to a simpler system that can be solved directly.  \n",
       "B) It can change the solution set if not done carefully.  \n",
       "C) It involves a finite number of steps.  \n",
       "D) It requires the system to be square.\n",
       "\n",
       "\n",
       "\n",
       "<br>\n",
       "\n",
       "## Answers\n",
       "\n",
       "##### 1. Which of the following statements about a homogeneous system of linear equations are true?  \n",
       "A) ‚úì Always has the trivial solution $ x=0 $.  \n",
       "B) ‚úó It *can* have infinitely many solutions if the system is underdetermined.  \n",
       "C) ‚úì The system is written as $ Ax=0 $.  \n",
       "D) ‚úó It does *not* always have a unique solution; trivial solution is guaranteed but not uniqueness.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 2. Which of the following are elementary row operations?  \n",
       "A) ‚úó Multiplying a row by zero destroys information and is not allowed.  \n",
       "B) ‚úì Interchanging two rows is a valid elementary operation.  \n",
       "C) ‚úì Adding a multiple of one row to another is elementary.  \n",
       "D) ‚úì Multiplying a row by a non-zero constant is elementary.\n",
       "\n",
       "**Correct:** B, C, D\n",
       "\n",
       "\n",
       "##### 3. Two linear systems are said to be equivalent if:  \n",
       "A) ‚úó Having the same coefficient matrix does not guarantee equivalence if constants differ.  \n",
       "B) ‚úì One can be obtained from the other by elementary operations.  \n",
       "C) ‚úó Having the same augmented matrix means identical systems, but equivalence is about solution sets.  \n",
       "D) ‚úì Equivalent systems have the same solution set.\n",
       "\n",
       "**Correct:** B, D\n",
       "\n",
       "\n",
       "##### 4. Which of the following are possible outcomes when solving a system $ Ax = b $?  \n",
       "A) ‚úì No solution is possible if inconsistent.  \n",
       "B) ‚úì Exactly one solution if $ A $ is invertible.  \n",
       "C) ‚úì Infinitely many solutions if system is underdetermined or dependent.  \n",
       "D) ‚úó Solutions can exist even if $ A $ is not invertible (infinitely many or none).\n",
       "\n",
       "**Correct:** A, B, C\n",
       "\n",
       "\n",
       "##### 5. In Gaussian elimination, the pivot element is:  \n",
       "A) ‚úì Used to eliminate variables below it.  \n",
       "B) ‚úó Not always the largest element in the matrix, but ideally large in its column.  \n",
       "C) ‚úì Usually the diagonal element in the current step.  \n",
       "D) ‚úì Must not be zero to avoid division by zero.\n",
       "\n",
       "**Correct:** A, C, D\n",
       "\n",
       "\n",
       "##### 6. What is the main purpose of partial pivoting in Gaussian elimination?  \n",
       "A) ‚úì Avoid division by zero by swapping rows.  \n",
       "B) ‚úì Reduce round-off errors by choosing a larger pivot.  \n",
       "C) ‚úó It does *not* reorder variables, only rows.  \n",
       "D) ‚úì Ensures pivot is largest in column below current row.\n",
       "\n",
       "**Correct:** A, B, D\n",
       "\n",
       "\n",
       "##### 7. Which of the following statements about the augmented matrix $[A|b]$ are true?  \n",
       "A) ‚úì Combines coefficient matrix and constants vector.  \n",
       "B) ‚úó Elementary row operations *do not* change the solution set.  \n",
       "C) ‚úì Used to perform Gaussian elimination.  \n",
       "D) ‚úó Not always square; depends on number of equations vs unknowns.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 8. Which of the following are true about ill-conditioned systems?  \n",
       "A) ‚úì Small changes cause large changes in solutions.  \n",
       "B) ‚úó They are *not* easy to solve numerically; they are sensitive.  \n",
       "C) ‚úì Have a large condition number.  \n",
       "D) ‚úì Round-off errors significantly affect solutions.\n",
       "\n",
       "**Correct:** A, C, D\n",
       "\n",
       "\n",
       "##### 9. Which of the following are inverse operations of elementary row operations?  \n",
       "A) ‚úì Interchanging the same two rows again reverses the swap.  \n",
       "B) ‚úó Multiplying by zero is not an elementary operation and cannot be reversed.  \n",
       "C) ‚úì Dividing by the same non-zero constant reverses multiplication.  \n",
       "D) ‚úì Replacing a row by itself minus the same multiple reverses addition.\n",
       "\n",
       "**Correct:** A, C, D\n",
       "\n",
       "\n",
       "##### 10. Which of the following are true about the back substitution step in Gaussian elimination?  \n",
       "A) ‚úì Starts from last equation upward.  \n",
       "B) ‚úì Requires upper triangular matrix.  \n",
       "C) ‚úó Cannot be performed before forward elimination.  \n",
       "D) ‚úì Solves variables one at a time by substitution.\n",
       "\n",
       "**Correct:** A, B, D\n",
       "\n",
       "\n",
       "##### 11. Which of the following statements about the coefficient matrix $ A $ are correct?  \n",
       "A) ‚úó Constants are in vector $ b $, not in $ A $.  \n",
       "B) ‚úó $ A $ is not always square; can be rectangular.  \n",
       "C) ‚úì Contains coefficients $ a_{ij} $ of variables.  \n",
       "D) ‚úì If invertible (square and full rank), guarantees unique solution.\n",
       "\n",
       "**Correct:** C, D\n",
       "\n",
       "\n",
       "##### 12. When is complete pivoting used, and what is its main drawback?  \n",
       "A) ‚úì Swaps rows and columns to place largest element as pivot.  \n",
       "B) ‚úì Rarely used because it changes variable order, complicating solution.  \n",
       "C) ‚úó Does not guarantee no division by zero in all cases, but reduces risk.  \n",
       "D) ‚úó More complex and computationally expensive than partial pivoting.\n",
       "\n",
       "**Correct:** A, B\n",
       "\n",
       "\n",
       "##### 13. Which of the following are true about the solution set of two equivalent linear systems?  \n",
       "A) ‚úì They have exactly the same solutions.  \n",
       "B) ‚úó One cannot have more solutions than the other if equivalent.  \n",
       "C) ‚úì Elementary operations preserve solution sets.  \n",
       "D) ‚úó Augmented matrices may differ after operations but represent equivalent systems.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 14. Which of the following can cause failure or inaccuracies in Gaussian elimination?  \n",
       "A) ‚úì Pivot element zero causes division by zero.  \n",
       "B) ‚úì Very small pivot causes large round-off errors.  \n",
       "C) ‚úó Partial pivoting is designed to prevent these issues.  \n",
       "D) ‚úì Round-off errors accumulate during elimination.\n",
       "\n",
       "**Correct:** A, B, D\n",
       "\n",
       "\n",
       "##### 15. Scaled partial pivoting differs from partial pivoting because:  \n",
       "A) ‚úì It considers relative size of elements in each row.  \n",
       "B) ‚úó Does not swap columns, only rows.  \n",
       "C) ‚úì Selects pivot based on largest absolute value divided by largest element in row.  \n",
       "D) ‚úó Used generally, not only for ill-conditioned systems.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 16. Which of the following statements about the augmented matrix after forward elimination are true?  \n",
       "A) ‚úó It is in upper triangular form *only* in the coefficient part, not necessarily the entire augmented matrix.  \n",
       "B) ‚úì Can be used for back substitution to find solution.  \n",
       "C) ‚úó Zeros are below the main diagonal, not above.  \n",
       "D) ‚úì Zeros appear below the main diagonal after elimination.\n",
       "\n",
       "**Correct:** B, D\n",
       "\n",
       "\n",
       "##### 17. Which of the following are true about the system $ Ax = 0 $?  \n",
       "A) ‚úì Always consistent because trivial solution $ x=0 $ exists.  \n",
       "B) ‚úì Infinitely many solutions if $ A $ is singular (non-invertible).  \n",
       "C) ‚úó Has unique trivial solution if $ A $ is invertible.  \n",
       "D) ‚úì Trivial solution is always a solution.\n",
       "\n",
       "**Correct:** A, B, D\n",
       "\n",
       "\n",
       "##### 18. Which of the following statements about row equivalence of matrices are correct?  \n",
       "A) ‚úì Row equivalence means one matrix can be obtained from the other by elementary row operations.  \n",
       "B) ‚úó Row equivalence does *not* guarantee same determinant; determinant can change sign.  \n",
       "C) ‚úì Row equivalent matrices represent equivalent linear systems.  \n",
       "D) ‚úì Row equivalence preserves rank.\n",
       "\n",
       "**Correct:** A, C, D\n",
       "\n",
       "\n",
       "##### 19. Which of the following describe the effect of round-off errors in solving linear systems?  \n",
       "A) ‚úì Can cause large errors in ill-conditioned systems.  \n",
       "B) ‚úó Not negligible in all numerical methods; can be significant.  \n",
       "C) ‚úì Pivoting helps minimize round-off errors.  \n",
       "D) ‚úó Round-off errors can still affect well-conditioned systems, but less severely.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 20. Which of the following are true about the method of solving the system by elementary operations?  \n",
       "A) ‚úì Leads to a simpler system solvable directly.  \n",
       "B) ‚úó Does *not* change solution set if done correctly.  \n",
       "C) ‚úì Requires a finite number of steps.  \n",
       "D) ‚úó Does *not* require the system to be square; works for rectangular systems too.\n",
       "\n",
       "**Correct:** A, C"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from source.render import render\n",
    "render(1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
