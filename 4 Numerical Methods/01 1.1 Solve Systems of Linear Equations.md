## 1.1 Solve Systems of Linear Equations

## Key Points

#### 1. üßÆ Systems of Linear Equations  
- A system of linear equations can be written as $Ax = b$, where $A$ is the coefficient matrix, $x$ is the vector of unknowns, and $b$ is the constants vector.  
- The system is **homogeneous** if all $b_i = 0$; otherwise, it is **non-homogeneous**.  
- A system can have a **unique solution**, **infinitely many solutions**, or **no solution**.

#### 2. üîÑ Elementary Operations and Equivalent Systems  
- Elementary operations include:  
  1. Interchanging two equations (or rows).  
  2. Multiplying an equation (or row) by a non-zero constant.  
  3. Replacing an equation (or row) by itself plus a multiple of another equation (or row).  
- Two systems are **equivalent** if one can be obtained from the other by a finite number of elementary operations.  
- Equivalent systems have the **same set of solutions**.

#### 3. üî∫ Gaussian Elimination Method  
- Gaussian elimination transforms the augmented matrix into an **upper triangular form** using elementary row operations.  
- After forward elimination, the system is solved by **back substitution** starting from the last variable.  
- The **pivot element** is the element used to eliminate variables below it in a column.

#### 4. ‚ö†Ô∏è Pivoting and Numerical Stability  
- If the pivot element is zero or very small, division by zero or large round-off errors can occur.  
- **Partial pivoting** swaps rows to place the largest absolute value in the pivot position to avoid these issues.  
- **Complete pivoting** swaps both rows and columns but is rarely used due to complexity.  
- **Scaled partial pivoting** considers the relative size of elements in each row before swapping.

#### 5. üìä Ill-Conditioned vs Well-Conditioned Systems  
- A **well-conditioned** system‚Äôs solution changes little with small changes in coefficients or constants.  
- An **ill-conditioned** system‚Äôs solution changes significantly with small changes, making it sensitive to round-off errors.  
- The **condition number** measures how ill-conditioned a matrix is; a large condition number indicates ill-conditioning.

#### 6. üìù Additional Key Points  
- The augmented matrix $[A|b]$ combines the coefficient matrix and constants for easier manipulation.  
- Elementary row operations have corresponding inverse operations, ensuring reversibility.  
- Pivoting minimizes round-off errors and avoids division by zero during elimination.



<br>

## Study Notes

### 1. üßÆ Introduction to Systems of Linear Equations

A **system of linear equations** is a collection of one or more linear equations involving the same set of variables. For example, if you have variables $x_1, x_2, \ldots, x_n$, a system of $m$ linear equations looks like this:


$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1 \\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = b_2 \\
\vdots \\
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = b_m
\end{cases}
$$


Here, the $a_{ij}$ are coefficients (real numbers), and the $b_i$ are constants on the right side of the equations.

#### Key Concepts:
- **Homogeneous system:** When all $b_i = 0$, the system is called *homogeneous*. It always has at least the trivial solution $x = 0$.
- **Non-homogeneous system:** When at least one $b_i \neq 0$, the system is *non-homogeneous*.
- The system can be written compactly as $Ax = b$, where:
  - $A$ is the **coefficient matrix** (contains all $a_{ij}$),
  - $x$ is the vector of unknowns,
  - $b$ is the constants vector.
- The **augmented matrix** $[A|b]$ combines the coefficient matrix and the constants for easier manipulation.

#### Possible outcomes when solving $Ax = b$:
- **Unique solution:** Exactly one set of values for $x$ satisfies all equations.
- **Infinitely many solutions:** There are multiple solutions, often due to dependent equations.
- **No solution:** The system is inconsistent (e.g., parallel lines that never intersect).


### 2. üîÑ Elementary Operations and Equivalent Systems

To solve systems of linear equations, we often manipulate the equations to simplify them. These manipulations are called **elementary operations** and are crucial because they do not change the solution set.

#### The three elementary operations are:

1. **Interchange two equations:** Swap the positions of two equations.
2. **Multiply an equation by a non-zero constant:** Scale an entire equation by a constant $c \neq 0$.
3. **Replace an equation by itself plus a multiple of another equation:** For example, replace equation $k$ by $\text{equation } k + c \times \text{equation } j$.

These operations are reversible, meaning you can undo them by applying inverse operations.

#### Why are these important?

- Applying these operations transforms the system into an **equivalent system** ‚Äî one that has exactly the same solutions as the original.
- This allows us to simplify the system step-by-step until it becomes easy to solve.

#### Row operations on matrices:

When working with matrices, these operations correspond to **elementary row operations**:

- Swap two rows.
- Multiply a row by a non-zero constant.
- Add a multiple of one row to another row.

Two matrices are **row-equivalent** if one can be obtained from the other by a finite sequence of these row operations.


### 3. üî∫ Gaussian Elimination Method

**Gaussian elimination** is a systematic procedure to solve linear systems by transforming the augmented matrix into an **upper triangular form** (all zeros below the main diagonal). Once in this form, the system can be solved easily by **back substitution**.

#### How Gaussian elimination works:

1. **Forward elimination:**
   - Start with the first column and eliminate the variable $x_1$ from all rows below the first.
   - Move to the second column and eliminate $x_2$ from all rows below the second.
   - Continue this process until the matrix is in upper triangular form.

2. **Back substitution:**
   - Solve for the last variable $x_n$ from the last equation.
   - Substitute $x_n$ into the second last equation to solve for $x_{n-1}$.
   - Continue substituting back until all variables are found.

#### Important notes:

- The **pivot element** is the element in the current row and column used to eliminate variables below it.
- The process relies on the pivot element being non-zero to avoid division by zero.


### 4. ‚ö†Ô∏è Pitfalls and Pivoting in Gaussian Elimination

While Gaussian elimination is powerful, it has some challenges:

#### Division by zero:

- If the pivot element is zero, you cannot divide by it to eliminate variables.
- This can happen if the matrix has zeros on the diagonal during elimination.

#### Small pivot elements and round-off errors:

- Even if the pivot is not zero but very small compared to other elements, numerical errors can become significant.
- This can lead to inaccurate solutions due to **round-off errors** in computer calculations.

#### Pivoting techniques to avoid these problems:

- **Partial pivoting:** Before eliminating variables in a column, swap the current row with a row below that has the largest absolute value in that column. This ensures the pivot element is as large as possible, reducing round-off errors.
- **Complete pivoting:** Swap both rows and columns to place the largest element in the pivot position. This is more complex and less commonly used because it changes the order of variables.
- **Scaled partial pivoting:** Takes into account the relative size of elements in each row to decide which row to swap, improving stability.


### 5. üìä Ill-Conditioned vs Well-Conditioned Systems

When solving linear systems numerically, the **condition** of the coefficient matrix $A$ is crucial.

#### Well-conditioned system:

- Small changes in the coefficients or constants lead to small changes in the solution.
- These systems are stable and reliable to solve numerically.

#### Ill-conditioned system:

- Small changes in the coefficients or constants cause large changes in the solution.
- These systems are sensitive to round-off errors and numerical instability.
- The **condition number** of a matrix measures this sensitivity. A large condition number indicates ill-conditioning.

#### Why does this matter?

- Ill-conditioned systems are difficult to solve accurately using numerical methods.
- Round-off errors, which are inevitable in computer calculations, can cause large errors in the solution.
- When possible, avoid ill-conditioned systems or use specialized numerical techniques to handle them.


### 6. üìù Summary and Practical Tips

- Systems of linear equations can be solved using **direct methods** like Gaussian elimination or **iterative methods** (not covered here).
- Use **elementary row operations** to simplify systems without changing their solutions.
- Apply **Gaussian elimination** to reduce the system to upper triangular form, then solve by back substitution.
- Always check for zero or small pivot elements to avoid division by zero or large numerical errors.
- Use **pivoting** (especially partial pivoting) to improve numerical stability.
- Be aware of the condition of your system; ill-conditioned systems require careful handling.
- Understanding these concepts is essential for implementing reliable numerical algorithms for solving linear systems.