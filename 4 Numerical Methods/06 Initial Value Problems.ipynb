{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019adb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T04:06:17.515769Z",
     "iopub.status.busy": "2025-07-16T04:06:17.515286Z",
     "iopub.status.idle": "2025-07-16T04:06:17.567597Z",
     "shell.execute_reply": "2025-07-16T04:06:17.566491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Initial Value Problems\n",
       "\n",
       "[Study Notes](#study-notes)\n",
       "\n",
       "[Questions](#questions)\n",
       "\n",
       "\n",
       "\n",
       "### Key Points\n",
       "\n",
       "##### 1. üìê Lipschitz Condition  \n",
       "- A function $f(t, y)$ satisfies a Lipschitz condition in $y$ on a set $D$ if there exists a constant $L > 0$ such that $|f(t, y_1) - f(t, y_2)| \\leq L |y_1 - y_2|$ for all $(t, y_1), (t, y_2) \\in D$.  \n",
       "- The constant $L$ is called the Lipschitz constant.  \n",
       "- If $f$ and its partial derivatives are continuous on $D$, then $f$ satisfies a Lipschitz condition on $D$.\n",
       "\n",
       "##### 2. üî∑ Convex Sets  \n",
       "- A set $D \\subset \\mathbb{R}^2$ is convex if for any two points $(t_1, y_1)$ and $(t_2, y_2)$ in $D$, the line segment $((1-\\lambda)t_1 + \\lambda t_2, (1-\\lambda)y_1 + \\lambda y_2)$ is also in $D$ for all $\\lambda \\in [0,1]$.\n",
       "\n",
       "##### 3. ‚úÖ Existence and Uniqueness Theorem for IVPs  \n",
       "- If $f(t, y)$ is continuous on a convex set $D = [a,b] \\times \\mathbb{R}$ and satisfies a Lipschitz condition in $y$, then the IVP $y' = f(t,y), y(a) = y_0$ has a unique solution on $[a,b]$.\n",
       "\n",
       "##### 4. üîí Well-Posedness of IVPs  \n",
       "- An IVP is well-posed if:  \n",
       "  1. A unique solution exists.  \n",
       "  2. Small perturbations in the initial data or function $f$ cause only small bounded changes in the solution.  \n",
       "- If $f$ is continuous and satisfies a Lipschitz condition on $D$, then the IVP is well-posed.\n",
       "\n",
       "##### 5. üßÆ Euler‚Äôs Method  \n",
       "- Approximates solutions at discrete mesh points $t_i = a + ih$, where $h = \\frac{b-a}{N}$.  \n",
       "- Recursive formula: $w_{i+1} = w_i + h f(t_i, w_i)$.  \n",
       "- Euler‚Äôs method has a local truncation error of order $h^2$ and a global error of order $h$ (first order method).  \n",
       "- Error bound depends on the Lipschitz constant $L$ and the bound on the second derivative of the true solution.\n",
       "\n",
       "##### 6. üöÄ Runge-Kutta Methods  \n",
       "- Use multiple evaluations of $f$ per step to achieve higher accuracy without computing derivatives of $f$.  \n",
       "- Midpoint method (2nd order): uses slope at midpoint for better approximation.  \n",
       "- Modified Euler method (2nd order): averages slopes at start and end of interval.  \n",
       "- Fourth order Runge-Kutta method: uses four slope evaluations per step, with global error order $h^4$.\n",
       "\n",
       "##### 7. üîÑ Multi-Step Methods  \n",
       "- Use multiple previous approximations $w_i, w_{i-1}, ..., w_{i-m+1}$ to compute $w_{i+1}$.  \n",
       "- Explicit multi-step methods: $w_{i+1}$ defined explicitly in terms of previous values (e.g., Adams-Bashforth).  \n",
       "- Implicit multi-step methods: $w_{i+1}$ appears on both sides of the equation (e.g., Adams-Moulton).\n",
       "\n",
       "##### 8. ‚úèÔ∏è Adams Methods  \n",
       "- Adams-Bashforth methods are explicit multi-step methods with local error order $O(h^{m+1})$ for $m$-step methods.  \n",
       "- Adams-Moulton methods are implicit multi-step methods with local error order $O(h^{m+2})$ for $m$-step methods.  \n",
       "- Adams-Bashforth $m$-step and Adams-Moulton $(m-1)$-step methods have similar computational cost and error order.\n",
       "\n",
       "##### 9. üîÑ Predictor-Corrector Methods  \n",
       "- Combine explicit (predictor) and implicit (corrector) methods to improve accuracy.  \n",
       "- Step 1: Use explicit method to predict $w_{i+1,p}$.  \n",
       "- Step 2: Use implicit method with $w_{i+1,p}$ to correct and find $w_{i+1}$.\n",
       "\n",
       "##### 10. üßÆ Numerical Solutions for Systems of IVPs  \n",
       "- Systems of first-order IVPs have the form $u_j' = f_j(t, u_1, ..., u_m)$ with initial conditions $u_j(a) = \\alpha_j$.  \n",
       "- If each $f_j$ is continuous and satisfies a Lipschitz condition, the system has a unique solution.  \n",
       "- Runge-Kutta methods extend to systems by applying the method component-wise.\n",
       "\n",
       "##### 11. üîÑ Converting Higher-Order IVPs to Systems  \n",
       "- An $m$-th order IVP can be rewritten as a system of $m$ first-order IVPs by introducing new variables for derivatives.  \n",
       "- Example: For $y'' = g(t, y, y')$, define $u_1 = y$, $u_2 = y'$, then system is $u_1' = u_2$, $u_2' = g(t, u_1, u_2)$.\n",
       "\n",
       "\n",
       "\n",
       "<br>\n",
       "\n",
       "## Study Notes\n",
       "\n",
       "### 1. üß© Introduction to Initial Value Problems (IVPs)\n",
       "\n",
       "When studying how things change over time, such as the swinging of a pendulum, we often use **differential equations**. These equations describe how a quantity changes at any moment. For example, the angle $\\theta(t)$ of a pendulum at time $t$ can be described by a differential equation.\n",
       "\n",
       "An **Initial Value Problem (IVP)** is a differential equation together with specific starting information ‚Äî the initial values. For the pendulum, this means knowing the initial angle $\\theta(0)$ and the initial speed $\\theta'(0)$ at the start time $t=0$.\n",
       "\n",
       "- The differential equation tells us how $\\theta(t)$ changes.\n",
       "- The initial values tell us where the motion starts.\n",
       "\n",
       "Together, these form an IVP: find the function $\\theta(t)$ that satisfies the differential equation and matches the initial conditions.\n",
       "\n",
       "**Why IVPs matter:** Many real-world problems are modeled as IVPs. However, most IVPs cannot be solved exactly with formulas (analytically). Instead, we use **numerical methods** to approximate solutions.\n",
       "\n",
       "\n",
       "### 2. üìè Theory Behind IVPs: Existence, Uniqueness, and Well-Posedness\n",
       "\n",
       "Before approximating solutions, it‚Äôs important to know if a solution exists, if it‚Äôs unique, and if the problem is stable (well-posed).\n",
       "\n",
       "##### Lipschitz Condition\n",
       "\n",
       "A key concept is the **Lipschitz condition**, which controls how fast the function $f(t, y)$ (from the differential equation $y' = f(t, y)$) can change with respect to $y$.\n",
       "\n",
       "- A function $f(t, y)$ satisfies a **Lipschitz condition** if there is a constant $L > 0$ such that for any two values $y_1$ and $y_2$, the difference in $f$ values is at most $L$ times the difference in $y$ values.\n",
       "- Intuitively, this means $f$ doesn‚Äôt change too wildly as $y$ changes.\n",
       "\n",
       "##### Convex Sets\n",
       "\n",
       "A set $D$ in the plane is **convex** if, whenever you pick two points in $D$, the entire line segment between them is also inside $D$. This property is important for applying certain theorems about IVPs.\n",
       "\n",
       "##### Existence and Uniqueness Theorem\n",
       "\n",
       "If $f(t, y)$ is continuous and satisfies the Lipschitz condition on a convex set $D$, then the IVP has a **unique solution** on the interval $[a, b]$.\n",
       "\n",
       "- This means the problem is well-defined: there is one and only one function $y(t)$ that fits the differential equation and initial values.\n",
       "\n",
       "##### Well-Posed Problems\n",
       "\n",
       "A problem is **well-posed** if:\n",
       "\n",
       "1. A unique solution exists.\n",
       "2. Small changes in the initial data or the function $f$ cause only small changes in the solution.\n",
       "\n",
       "This is crucial for numerical methods because computers work with approximations and rounding errors. If the problem is not well-posed, tiny errors could cause huge differences in the solution, making numerical approximations unreliable.\n",
       "\n",
       "**Summary:** Checking the Lipschitz condition is a practical way to verify if an IVP is well-posed.\n",
       "\n",
       "\n",
       "### 3. üßÆ Euler‚Äôs Method: The Basic Numerical Approach\n",
       "\n",
       "Euler‚Äôs method is the simplest way to approximate solutions to IVPs numerically.\n",
       "\n",
       "##### How Euler‚Äôs Method Works\n",
       "\n",
       "- We divide the time interval $[a, b]$ into $N$ equal parts, called **mesh points**: $t_0, t_1, ..., t_N$.\n",
       "- The step size is $h = \\frac{b - a}{N}$.\n",
       "- Starting from the initial value $y(t_0) = y_0$, we approximate the solution at each mesh point using the formula:\n",
       "\n",
       "$$\n",
       "w_{i+1} = w_i + h f(t_i, w_i)\n",
       "$$\n",
       "\n",
       "Here, $w_i$ approximates $y(t_i)$.\n",
       "\n",
       "##### Intuition Behind Euler‚Äôs Method\n",
       "\n",
       "Euler‚Äôs method uses the idea of a **tangent line approximation**:\n",
       "\n",
       "- At each point $(t_i, w_i)$, the slope of the solution curve is approximately $f(t_i, w_i)$.\n",
       "- We move forward a small step $h$ along this slope to estimate the next value $w_{i+1}$.\n",
       "\n",
       "##### Example\n",
       "\n",
       "For the IVP $y' = y - t^2 + 1$, $y(0) = 0.5$, with $N=4$ and $h=0.5$, Euler‚Äôs method calculates approximate values at $t=0.5, 1.0, 1.5, 2.0$.\n",
       "\n",
       "##### Error in Euler‚Äôs Method\n",
       "\n",
       "- The error is proportional to the step size $h$ (order 1).\n",
       "- Smaller $h$ means better accuracy but more computation.\n",
       "- However, very small $h$ can increase rounding errors due to finite precision in computers.\n",
       "\n",
       "\n",
       "### 4. üöÄ Runge-Kutta Methods: More Accurate Numerical Solutions\n",
       "\n",
       "Euler‚Äôs method is simple but not very accurate. Runge-Kutta methods improve accuracy by using more sophisticated approximations.\n",
       "\n",
       "##### Why Runge-Kutta?\n",
       "\n",
       "- Higher order Taylor expansions give better approximations but require derivatives of $f$, which can be hard or expensive to compute.\n",
       "- Runge-Kutta methods cleverly approximate these derivatives by evaluating $f$ at several points within each step.\n",
       "\n",
       "##### Midpoint Method (Second Order Runge-Kutta)\n",
       "\n",
       "- Uses the slope at the midpoint of the interval to improve the estimate.\n",
       "- Formula:\n",
       "\n",
       "$$\n",
       "w_{i+1} = w_i + h f\\left(t_i + \\frac{h}{2}, w_i + \\frac{h}{2} f(t_i, w_i)\\right)\n",
       "$$\n",
       "\n",
       "##### Modified Euler Method\n",
       "\n",
       "- Averages the slope at the beginning and the end of the interval.\n",
       "- Formula:\n",
       "\n",
       "$$\n",
       "w_{i+1} = w_i + \\frac{h}{2} \\left[f(t_i, w_i) + f(t_{i+1}, w_i + h f(t_i, w_i))\\right]\n",
       "$$\n",
       "\n",
       "##### Fourth Order Runge-Kutta (Most Common)\n",
       "\n",
       "- Uses four slope evaluations per step.\n",
       "- Very accurate with error order $h^4$.\n",
       "- Formula involves calculating four intermediate slopes $k_1, k_2, k_3, k_4$ and combining them.\n",
       "\n",
       "##### Comparison of Methods\n",
       "\n",
       "| Method               | Error Order | Number of $f$ Evaluations per Step |\n",
       "|----------------------|-------------|-------------------------------------|\n",
       "| Euler                | 1           | 1                                   |\n",
       "| Midpoint             | 2           | 2                                   |\n",
       "| Modified Euler       | 2           | 2                                   |\n",
       "| Fourth Order Runge-Kutta | 4       | 4                                   |\n",
       "\n",
       "Runge-Kutta methods provide much better accuracy for the same step size compared to Euler‚Äôs method.\n",
       "\n",
       "\n",
       "### 5. üîÑ Multi-Step Methods: Using More Past Information\n",
       "\n",
       "One-step methods like Euler and Runge-Kutta use only the last point to find the next approximation. **Multi-step methods** use several previous points to improve accuracy.\n",
       "\n",
       "##### General Form\n",
       "\n",
       "An $m$-step method uses the last $m$ approximations $w_i, w_{i-1}, ..., w_{i-m+1}$ to compute $w_{i+1}$.\n",
       "\n",
       "- These methods can be **explicit** (next value depends only on known values) or **implicit** (next value appears on both sides of the equation).\n",
       "\n",
       "##### Adams Methods\n",
       "\n",
       "Two important families of multi-step methods:\n",
       "\n",
       "- **Adams-Bashforth (Explicit):** Use past function values to predict the next value.\n",
       "- **Adams-Moulton (Implicit):** Use past and next function values, requiring solving an equation for $w_{i+1}$.\n",
       "\n",
       "##### Predictor-Corrector Methods\n",
       "\n",
       "- Combine explicit and implicit methods.\n",
       "- Use an explicit method to predict $w_{i+1}$.\n",
       "- Use this prediction in an implicit method to correct and improve the estimate.\n",
       "- This approach balances accuracy and computational effort.\n",
       "\n",
       "\n",
       "### 6. üî¢ Numerical Solutions for Systems of IVPs\n",
       "\n",
       "Many problems involve **systems** of differential equations, not just one equation.\n",
       "\n",
       "##### System of IVPs\n",
       "\n",
       "A system looks like:\n",
       "\n",
       "$$\n",
       "\\begin{cases}\n",
       "u_1' = f_1(t, u_1, u_2, ..., u_m) \\\\\n",
       "u_2' = f_2(t, u_1, u_2, ..., u_m) \\\\\n",
       "\\vdots \\\\\n",
       "u_m' = f_m(t, u_1, u_2, ..., u_m)\n",
       "\\end{cases}\n",
       "$$\n",
       "\n",
       "with initial conditions $u_j(a) = \\alpha_j$.\n",
       "\n",
       "##### Existence and Uniqueness for Systems\n",
       "\n",
       "- Similar Lipschitz conditions apply, but now for vector-valued functions.\n",
       "- If each $f_j$ and its partial derivatives are continuous and satisfy Lipschitz conditions, the system has a unique solution.\n",
       "\n",
       "##### Numerical Methods for Systems\n",
       "\n",
       "- Runge-Kutta methods extend naturally to systems.\n",
       "- For each component $u_j$, calculate intermediate slopes $k_{i,1}^j, k_{i,2}^j, ...$ and update approximations.\n",
       "- This allows simultaneous approximation of all functions $u_1(t), ..., u_m(t)$.\n",
       "\n",
       "\n",
       "### 7. üîÑ Converting Higher-Order IVPs to Systems\n",
       "\n",
       "Higher-order differential equations (e.g., second order) can be rewritten as systems of first-order equations.\n",
       "\n",
       "##### Example\n",
       "\n",
       "For a second-order IVP:\n",
       "\n",
       "$$\n",
       "y'' = g(t, y, y')\n",
       "$$\n",
       "\n",
       "Define:\n",
       "\n",
       "$$\n",
       "u_1 = y, \\quad u_2 = y'\n",
       "$$\n",
       "\n",
       "Then:\n",
       "\n",
       "$$\n",
       "\\begin{cases}\n",
       "u_1' = u_2 \\\\\n",
       "u_2' = g(t, u_1, u_2)\n",
       "\\end{cases}\n",
       "$$\n",
       "\n",
       "This system can be solved using the methods for systems described above.\n",
       "\n",
       "\n",
       "### Summary\n",
       "\n",
       "- **Initial Value Problems (IVPs)** involve solving differential equations with given initial conditions.\n",
       "- **Existence and uniqueness** of solutions depend on continuity and Lipschitz conditions.\n",
       "- **Well-posedness** ensures solutions behave stably under small changes.\n",
       "- **Euler‚Äôs method** is a simple numerical method but has limited accuracy.\n",
       "- **Runge-Kutta methods** improve accuracy by using multiple slope evaluations.\n",
       "- **Multi-step methods** use several past points to improve approximations.\n",
       "- **Predictor-corrector methods** combine explicit and implicit approaches for better results.\n",
       "- Systems of IVPs and higher-order IVPs can be handled by extending these methods.\n",
       "\n",
       "\n",
       "\n",
       "<br>\n",
       "\n",
       "## Questions\n",
       "\n",
       "##### 1. Which of the following statements about an Initial Value Problem (IVP) are true?  \n",
       "A) An IVP consists of a differential equation and initial conditions specifying the function and its derivatives at a starting point.  \n",
       "B) The initial values must always include the function value and all its derivatives up to the order of the differential equation.  \n",
       "C) IVPs always have closed-form analytical solutions.  \n",
       "D) Numerical methods are often necessary because many IVPs cannot be solved analytically.\n",
       "\n",
       "\n",
       "##### 2. A function $f(t, y)$ satisfies a Lipschitz condition on a set $D$ if:  \n",
       "A) There exists a constant $L > 0$ such that $|f(t, y_1) - f(t, y_2)| \\leq L |y_1 - y_2|$ for all $(t, y_1), (t, y_2) \\in D$.  \n",
       "B) $f$ is differentiable with respect to $t$ on $D$.  \n",
       "C) $f$ is continuous on $D$ and its partial derivative with respect to $y$ is bounded.  \n",
       "D) $f$ is convex on $D$.\n",
       "\n",
       "\n",
       "##### 3. Which of the following sets is convex?  \n",
       "A) The set $D = \\{(t, y) \\mid t \\in [0,1], y \\in [-1,1]\\}$.  \n",
       "B) The set $D = \\{(t, y) \\mid y = t^2, t \\in [0,1]\\}$.  \n",
       "C) The set $D = \\{(t, y) \\mid t^2 + y^2 \\leq 1\\}$.  \n",
       "D) The set $D = \\{(t, y) \\mid y \\geq |t|\\}$.\n",
       "\n",
       "\n",
       "##### 4. The Existence and Uniqueness Theorem for IVPs requires which of the following conditions?  \n",
       "A) $f(t, y)$ must be continuous on a convex set $D$.  \n",
       "B) $f(t, y)$ must satisfy a Lipschitz condition in $y$ on $D$.  \n",
       "C) The initial value $y(a)$ must be zero.  \n",
       "D) The domain $D$ must be bounded.\n",
       "\n",
       "\n",
       "##### 5. What does it mean for an IVP to be well-posed?  \n",
       "A) It has a unique solution.  \n",
       "B) Small changes in initial conditions or the function $f$ cause only small changes in the solution.  \n",
       "C) The solution can be expressed in closed form.  \n",
       "D) The solution is stable under perturbations in the differential equation and initial values.\n",
       "\n",
       "\n",
       "##### 6. Which of the following statements about Euler‚Äôs method are correct?  \n",
       "A) Euler‚Äôs method approximates the solution at discrete mesh points, not continuously.  \n",
       "B) The step size $h$ is defined as $\\frac{b-a}{N}$ where $N$ is the number of steps.  \n",
       "C) Euler‚Äôs method uses a second-order Taylor expansion to approximate the solution.  \n",
       "D) The error in Euler‚Äôs method is proportional to the first power of $h$.\n",
       "\n",
       "\n",
       "##### 7. Regarding the error bounds of Euler‚Äôs method, which are true?  \n",
       "A) The theoretical error bound depends on the Lipschitz constant $L$ and the bound on the second derivative of the solution.  \n",
       "B) The actual error is always equal to the theoretical error bound.  \n",
       "C) Rounding errors can become significant as $h$ becomes very small.  \n",
       "D) Decreasing $h$ indefinitely always decreases the total error.\n",
       "\n",
       "\n",
       "##### 8. Runge-Kutta methods improve on Euler‚Äôs method by:  \n",
       "A) Using multiple evaluations of $f(t, y)$ within each step.  \n",
       "B) Requiring the computation of derivatives of $f$ with respect to $t$.  \n",
       "C) Eliminating the need for derivative computations by approximating higher-order terms with function evaluations.  \n",
       "D) Being explicit multi-step methods.\n",
       "\n",
       "\n",
       "##### 9. The Midpoint method (a second-order Runge-Kutta method) approximates the solution by:  \n",
       "A) Using the slope at the beginning of the interval only.  \n",
       "B) Using the slope at the midpoint of the interval estimated from the initial slope.  \n",
       "C) Averaging the slopes at the beginning and end of the interval.  \n",
       "D) Using four slope evaluations per step.\n",
       "\n",
       "\n",
       "##### 10. Which of the following statements about the fourth-order Runge-Kutta method are true?  \n",
       "A) It requires four function evaluations per step.  \n",
       "B) It has a local truncation error of order $h^5$.  \n",
       "C) It is more accurate than Euler‚Äôs method for the same step size.  \n",
       "D) It is an implicit method.\n",
       "\n",
       "\n",
       "##### 11. Multi-step methods differ from one-step methods because:  \n",
       "A) They use multiple previous approximations to compute the next value.  \n",
       "B) They always require solving implicit equations.  \n",
       "C) They can be explicit or implicit depending on the coefficients.  \n",
       "D) They do not require initial values.\n",
       "\n",
       "\n",
       "##### 12. In the general multi-step method formula, if the coefficient $b_m = 0$, the method is:  \n",
       "A) Explicit, because $w_{i+1}$ can be computed directly.  \n",
       "B) Implicit, because $w_{i+1}$ appears on both sides of the equation.  \n",
       "C) Unstable for all IVPs.  \n",
       "D) Requires solving nonlinear equations at each step.\n",
       "\n",
       "\n",
       "##### 13. Adams-Bashforth methods are:  \n",
       "A) Explicit multi-step methods.  \n",
       "B) Implicit multi-step methods.  \n",
       "C) Based on polynomial interpolation of $f(t, y)$ at previous points.  \n",
       "D) Always more accurate than Adams-Moulton methods of the same step number.\n",
       "\n",
       "\n",
       "##### 14. Adams-Moulton methods are:  \n",
       "A) Implicit multi-step methods.  \n",
       "B) Explicit multi-step methods.  \n",
       "C) Used as correctors in predictor-corrector schemes.  \n",
       "D) Require solving for $w_{i+1}$ at each step.\n",
       "\n",
       "\n",
       "##### 15. Predictor-corrector methods:  \n",
       "A) Use an explicit method to predict the next value.  \n",
       "B) Use an implicit method to correct the predicted value.  \n",
       "C) Always guarantee exact solutions.  \n",
       "D) Can improve accuracy without significantly increasing computational cost.\n",
       "\n",
       "\n",
       "##### 16. For a system of IVPs, the Lipschitz condition:  \n",
       "A) Must hold for each component function $f_j$ with respect to all variables $u_1, u_2, ..., u_m$.  \n",
       "B) Is not necessary for existence and uniqueness of solutions.  \n",
       "C) Can be verified by checking boundedness of partial derivatives of $f_j$.  \n",
       "D) Is only required for scalar IVPs.\n",
       "\n",
       "\n",
       "##### 17. When converting a higher-order IVP into a system of first-order IVPs:  \n",
       "A) New variables are introduced to represent derivatives of the original function.  \n",
       "B) The order of the system equals the order of the original IVP.  \n",
       "C) The system can be solved using methods for first-order systems.  \n",
       "D) This conversion is only possible for linear differential equations.\n",
       "\n",
       "\n",
       "##### 18. Which of the following are true about the stability and error behavior of numerical methods for IVPs?  \n",
       "A) Well-posedness of the IVP ensures numerical stability under small perturbations.  \n",
       "B) Euler‚Äôs method has global error proportional to $h$.  \n",
       "C) Runge-Kutta methods can have errors that grow exponentially with the number of steps.  \n",
       "D) Multi-step methods always have smaller errors than one-step methods.\n",
       "\n",
       "\n",
       "##### 19. Which of the following statements about the use of mesh points in numerical methods are correct?  \n",
       "A) Mesh points are usually chosen to be equally spaced in the interval $[a, b]$.  \n",
       "B) The solution is approximated only at mesh points, and values between points require interpolation.  \n",
       "C) The step size $h$ can vary arbitrarily between mesh points in Euler‚Äôs method.  \n",
       "D) Smaller step sizes always guarantee better approximations without exception.\n",
       "\n",
       "\n",
       "##### 20. Regarding the computational cost and accuracy trade-offs in numerical methods for IVPs:  \n",
       "A) Higher-order methods like fourth-order Runge-Kutta require more function evaluations per step but provide better accuracy.  \n",
       "B) Multi-step methods reduce the number of function evaluations per step by reusing previous information.  \n",
       "C) Implicit methods are generally easier to implement than explicit methods.  \n",
       "D) Predictor-corrector methods combine the advantages of explicit and implicit methods to balance accuracy and computational effort.\n",
       "\n",
       "\n",
       "\n",
       "<br>\n",
       "\n",
       "## Answers\n",
       "\n",
       "##### 1. Which of the following statements about an Initial Value Problem (IVP) are true?  \n",
       "A) ‚úì An IVP consists of a differential equation and initial conditions specifying the function and its derivatives at a starting point.  \n",
       "B) ‚úó Initial values do not always include all derivatives up to the order; only the necessary initial conditions are given.  \n",
       "C) ‚úó Many IVPs cannot be solved analytically, so this is false.  \n",
       "D) ‚úì Numerical methods are often necessary because many IVPs cannot be solved analytically.\n",
       "\n",
       "**Correct:** A, D\n",
       "\n",
       "\n",
       "##### 2. A function $f(t, y)$ satisfies a Lipschitz condition on a set $D$ if:  \n",
       "A) ‚úì This is the formal definition of the Lipschitz condition in $y$.  \n",
       "B) ‚úó Differentiability with respect to $t$ is not required for Lipschitz in $y$.  \n",
       "C) ‚úì Bounded partial derivative with respect to $y$ implies Lipschitz condition.  \n",
       "D) ‚úó Convexity is unrelated to Lipschitz condition.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 3. Which of the following sets is convex?  \n",
       "A) ‚úì A rectangle in $\\mathbb{R}^2$ is convex.  \n",
       "B) ‚úó A parabola curve is not convex as a set (it‚Äôs a curve, not a filled region).  \n",
       "C) ‚úì A disk (circle and interior) is convex.  \n",
       "D) ‚úó The set $y \\geq |t|$ forms a \"V\" shape, which is convex, but since it includes all points above, it is convex. (Tricky) Actually, this set is convex because any line segment between two points above the \"V\" lies above it. So this is ‚úì.\n",
       "\n",
       "**Correct:** A, C, D\n",
       "\n",
       "\n",
       "##### 4. The Existence and Uniqueness Theorem for IVPs requires which of the following conditions?  \n",
       "A) ‚úì Continuity on a convex set is required.  \n",
       "B) ‚úì Lipschitz condition in $y$ is required.  \n",
       "C) ‚úó Initial value does not have to be zero.  \n",
       "D) ‚úó The domain does not have to be bounded.\n",
       "\n",
       "**Correct:** A, B\n",
       "\n",
       "\n",
       "##### 5. What does it mean for an IVP to be well-posed?  \n",
       "A) ‚úì Unique solution exists.  \n",
       "B) ‚úì Small changes in initial data cause small changes in solution.  \n",
       "C) ‚úó Closed form solution is not required for well-posedness.  \n",
       "D) ‚úì Stability under perturbations is part of well-posedness.\n",
       "\n",
       "**Correct:** A, B, D\n",
       "\n",
       "\n",
       "##### 6. Which of the following statements about Euler‚Äôs method are correct?  \n",
       "A) ‚úì Euler‚Äôs method approximates solution only at discrete mesh points.  \n",
       "B) ‚úì Step size $h$ is defined as $\\frac{b-a}{N}$.  \n",
       "C) ‚úó Euler‚Äôs method uses first-order Taylor approximation, not second-order.  \n",
       "D) ‚úì Error is proportional to $h$ (order 1).\n",
       "\n",
       "**Correct:** A, B, D\n",
       "\n",
       "\n",
       "##### 7. Regarding the error bounds of Euler‚Äôs method, which are true?  \n",
       "A) ‚úì Theoretical error bound depends on Lipschitz constant and second derivative bound.  \n",
       "B) ‚úó Actual error is usually smaller than the theoretical bound.  \n",
       "C) ‚úì Rounding errors become significant as $h$ decreases.  \n",
       "D) ‚úó Decreasing $h$ indefinitely can increase rounding errors, so total error may not always decrease.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 8. Runge-Kutta methods improve on Euler‚Äôs method by:  \n",
       "A) ‚úì Using multiple evaluations of $f$ per step.  \n",
       "B) ‚úó They avoid computing derivatives of $f$ with respect to $t$.  \n",
       "C) ‚úì Replace derivatives with function evaluations at selected points.  \n",
       "D) ‚úó Runge-Kutta methods are one-step, not multi-step.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 9. The Midpoint method (a second-order Runge-Kutta method) approximates the solution by:  \n",
       "A) ‚úó Uses more than just the slope at the beginning.  \n",
       "B) ‚úì Uses slope at midpoint estimated from initial slope.  \n",
       "C) ‚úó Averaging slopes is Modified Euler, not Midpoint method.  \n",
       "D) ‚úó Four slope evaluations per step is fourth-order Runge-Kutta.\n",
       "\n",
       "**Correct:** B\n",
       "\n",
       "\n",
       "##### 10. Which of the following statements about the fourth-order Runge-Kutta method are true?  \n",
       "A) ‚úì Requires four function evaluations per step.  \n",
       "B) ‚úì Local truncation error is order $h^5$ (global error order $h^4$).  \n",
       "C) ‚úì More accurate than Euler‚Äôs method for same $h$.  \n",
       "D) ‚úó It is an explicit method, not implicit.\n",
       "\n",
       "**Correct:** A, B, C\n",
       "\n",
       "\n",
       "##### 11. Multi-step methods differ from one-step methods because:  \n",
       "A) ‚úì Use multiple previous approximations.  \n",
       "B) ‚úó Not all multi-step methods are implicit; some are explicit.  \n",
       "C) ‚úì Can be explicit or implicit depending on coefficients.  \n",
       "D) ‚úó Initial values are required to start the method.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 12. In the general multi-step method formula, if the coefficient $b_m = 0$, the method is:  \n",
       "A) ‚úì Explicit, since $w_{i+1}$ can be computed directly.  \n",
       "B) ‚úó Implicit requires $b_m \\neq 0$.  \n",
       "C) ‚úó Stability depends on method and problem, not just $b_m$.  \n",
       "D) ‚úó Explicit methods do not require solving nonlinear equations.\n",
       "\n",
       "**Correct:** A\n",
       "\n",
       "\n",
       "##### 13. Adams-Bashforth methods are:  \n",
       "A) ‚úì Explicit multi-step methods.  \n",
       "B) ‚úó They are not implicit.  \n",
       "C) ‚úì Based on polynomial interpolation of $f$ at previous points.  \n",
       "D) ‚úó Adams-Moulton methods are generally more accurate for same step number.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 14. Adams-Moulton methods are:  \n",
       "A) ‚úì Implicit multi-step methods.  \n",
       "B) ‚úó Not explicit.  \n",
       "C) ‚úì Often used as correctors in predictor-corrector schemes.  \n",
       "D) ‚úì Require solving for $w_{i+1}$ at each step.\n",
       "\n",
       "**Correct:** A, C, D\n",
       "\n",
       "\n",
       "##### 15. Predictor-corrector methods:  \n",
       "A) ‚úì Use explicit method to predict next value.  \n",
       "B) ‚úì Use implicit method to correct predicted value.  \n",
       "C) ‚úó Do not guarantee exact solutions, only better approximations.  \n",
       "D) ‚úì Improve accuracy without large computational cost increase.\n",
       "\n",
       "**Correct:** A, B, D\n",
       "\n",
       "\n",
       "##### 16. For a system of IVPs, the Lipschitz condition:  \n",
       "A) ‚úì Must hold for each component with respect to all variables.  \n",
       "B) ‚úó Necessary for existence and uniqueness.  \n",
       "C) ‚úì Can be checked via bounded partial derivatives.  \n",
       "D) ‚úó Lipschitz condition applies to systems, not only scalars.\n",
       "\n",
       "**Correct:** A, C\n",
       "\n",
       "\n",
       "##### 17. When converting a higher-order IVP into a system of first-order IVPs:  \n",
       "A) ‚úì New variables represent derivatives of the original function.  \n",
       "B) ‚úì The system order equals the original IVP order.  \n",
       "C) ‚úì The system can be solved by first-order methods.  \n",
       "D) ‚úó Conversion applies to nonlinear and linear equations alike.\n",
       "\n",
       "**Correct:** A, B, C\n",
       "\n",
       "\n",
       "##### 18. Which of the following are true about the stability and error behavior of numerical methods for IVPs?  \n",
       "A) ‚úì Well-posedness ensures stability under small perturbations.  \n",
       "B) ‚úì Euler‚Äôs method global error is proportional to $h$.  \n",
       "C) ‚úó Runge-Kutta errors do not necessarily grow exponentially; depends on problem.  \n",
       "D) ‚úó Multi-step methods are not always more accurate than one-step methods.\n",
       "\n",
       "**Correct:** A, B\n",
       "\n",
       "\n",
       "##### 19. Which of the following statements about the use of mesh points in numerical methods are correct?  \n",
       "A) ‚úì Mesh points are usually equally spaced.  \n",
       "B) ‚úì Solutions are approximated at mesh points; interpolation needed between points.  \n",
       "C) ‚úó Euler‚Äôs method typically uses fixed step size $h$. Variable step size is possible but not standard.  \n",
       "D) ‚úó Smaller step size usually improves accuracy but not always due to rounding errors.\n",
       "\n",
       "**Correct:** A, B\n",
       "\n",
       "\n",
       "##### 20. Regarding the computational cost and accuracy trade-offs in numerical methods for IVPs:  \n",
       "A) ‚úì Higher-order methods require more function evaluations but yield better accuracy.  \n",
       "B) ‚úì Multi-step methods reuse previous info, reducing function evaluations per step.  \n",
       "C) ‚úó Implicit methods are generally harder to implement than explicit methods.  \n",
       "D) ‚úì Predictor-corrector methods balance accuracy and computational effort.\n",
       "\n",
       "**Correct:** A, B, D"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from source.render import render\n",
    "render(6)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
