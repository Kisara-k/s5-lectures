[
  {
    "index": 1,
    "title": "1.1 Solve Systems of Linear Equations",
    "content": "Chapter I Solve Systems of Linear Equations. Introduction Numerical methods for solving linear systems of equations can generally be divided into two classes: • Direct methods. In the absence of roundoﬀerror such methods would yield the exact solution within a ﬁnite number of steps. • Iterative methods. These are methods that are useful for problems involving special, very large matrices. A linear system of m equations in n unknowns x1, x2, ..., xn is a set of equations of the form a11x1 + a12x2 + ... + a1nxn = b1 a21x1 + a22x2 + ... + a2nxn = b2 Rm : am1x1 + am2x2 + ... + amnxn = bm where for 1 Æ i Æ n, and 1 Æ j Æ m; aij, bi œ R. Linear System in equation ( 1.1) is called homogeneous if b1 = b2 = ... = bm = 0 and non-homogeneous otherwise. We rewrite the above equations in the form Ax = b, where WWWU amn XXXV , x = WWWU XXXV. , and b = WWWU XXXV. , The matrix A is called the coeﬃcient matrix and the block matrix [A|b], is the augmented matrix of the linear system for a system of linear equations Ax = b, the system Ax = 0 is called the associated homogeneous system. When we solve system of linear equations, the system Ax = b, may have • A unique solution. • Inﬁnitely many solutions • No solution. Direct Method: Method of Solving Example 1.2.1 Let us solve the linear system. x + 7y + 3z = 11, x + y + z = 3, and 4x + 10y ≠z = 13. 1. The above linear system and the linear system (Interchange the ﬁrst two equations). have the same set of solutions. 2. Eliminating x from 2nd and 3rd equation, we get the linear system (obtained by subtracting the ﬁrst equation from the second equation.) (obtained by subtracting 4 times the ﬁrst equation from the third equation.) 3. Eliminating y from the last two equations of system, we get the system (obtained by subtracting the third equation from the second equation). divide the second equation by 2 (divide the second equation by 7) 5. Now, z = 1 implies y = 1 and x = 3 ≠(1 + 1) = 1.Or in-terms of a vector,the set of solution is Row Operations and Equivalent Systems Deﬁnition 1.2.1 (Elementary Operations) The following operations 1, 2 and 3 are called elementary operations 1. interchange of two equations, say “interchange the ith and jth equations”; (previous example part 01 ) 2. multiply a non-zero constant throughout an equation, say “multiply the ith equation by c ”= 0\" 3. replace an equation by itself plus a constant multiple of another equation, say “replace the kth equation by kth equation plus c times the jth equation”. So, in previous example the application of a ﬁnite number of elementary operations helped us to obtain a simpler system whose solution can be obtained directly. That is, after applying a ﬁnite number of elementary operations, a simpler linear system is obtained which can be easily solved. Note that the three elementary operations deﬁned above, have corresponding inverse operations, namely, 1. interchange the ith and jth equations, 2. divide the kth equation by c ”= 0 3. replace the kth equation by kth equation minus c times the jth equation. Deﬁnition 1.2.2 (Equivalent Linear Systems) Two linear systems are said to be equivalent if one can be ob- tained from the other by a ﬁnite number of elementary operations. Lemma 1.2.1 Let Ax = b be the linear system obtained from the linear system Cx = d by a single elementary operation. Then the linear systems Ax = b and Cx = d have the same set of solutions. Theorem 1.2.1 Two equivalent systems have the same set of solutions. Deﬁnition 1.2.3 (Elementary Row Operations) The elementary row operations are deﬁned as: • interchange of two rows, say “interchange the ith and jth rows”, denoted Ri ¡ Rj; Note: This process is called \"Pivoting\". The pivot element of a speciﬁc column is the element that is used to create zeros in the other entries in that column . • multiply a non-zero constant throughout a row, say multiply the kth row by c ”= 0, denoted cRk æ Rk • replace a row by itself plus a constant multiple of another row, say replace the kth row by kth row plus c times the jth row, denoted Rk + cRj æ Rk. In otherwords: any row can be replaced by a weighted linear combination of that row with any other row Deﬁnition 1.2.4 (Row Equivalent Matrices) Two matrices are said to be row-equivalent if one can be obtained from the other by a ﬁnite number of elementary row operations. Example 1.2.2 A= and B= are row equivalent. Gauss Elimination Method Gaussian Elimination is a simple and eﬃcient method to solve systems of linear equations Ax = b. In this method we reduce the system of equations to an equivalent upper triangular system which can be solved by backward substitution. Gaussian elimination is a method of solving a linear system a11x1 + a12x2 + ... + a1nxn = b1 a21x1 + a22x2 + ... + a2nxn = b2 Rn : an1x1 + an2x2 + ... + annxn = bn First we bringing up the augmented matrix WWWU ann XXXV Our goal is converting this matrix into an upper triangular form. WWWU cnn XXXV Forward Elimination of Unknowns The initial step for this process will be to eliminate the ﬁrst unknown, x1, from the second through the nth equations. Provided a11 ”= 0, we perform the operations for each j = 2, 3, ..., n to eliminate the coeﬃcient of x1 in each of these rows. More generally, we eliminate xi in each row below the ith for all values of i = 1, 2, ..., n ≠1 by performing for each j = i + 1, i + 2, ..., n provided ai ii ”= 0. This eliminates (changes the coeﬃcient to zero) xi in each row below the ith for all values of i = 1, 2, ..., n ≠1. The resulting matrix has the form: WWWWWWU XXXXXXV. Back Substitution The upper-triangle matrix can now be used to ﬁnd the solution of xn : This result can be back-substituted into the (n ≠l)th equation to solve for xn≠1. The procedure, which is repeated to evaluate the remaining xÕs, can be represented by the following formula: for i = n ≠1, n ≠2, ..., 1 In other-words: This system of linear equations can be reduced to upper-triangular matrix by applying row operations and can be solved for the unknowns by backward substitution. Example 1.3.1 Solve the linear system by Gauss elimination method. Solution: The corresponding augmented matrix is Now, let us apply Gauss elimination. Example 1.3.2 Solve the linear system by Gauss elimination method. Pitfalls of Elimination Method Whereas there are many systems of equations that can be solved with Gauss elimination, there are some pitfalls that must be explored before writing a general computer program to implement the method. During both the elimination and the back-substitution phases, it is possible that a division by zero can occur. For example, if we use Gauss elimination to solve Obvious problems occur as the pivot element, a11 = 0 is zero, because the normalization step leads to division by zero. The technique of pivoting has been developed to partially avoid these problems. Problems may also arise when the pivot element is close to, rather than exactly equal to zero because if the magnitude of the pivot element is small compared to the other elements, then round-oﬀerrors can be introduced. Therefore, before each row is normalized, it is advantageous to determine the largest available coeﬃcient in the column below the pivot element. The rows can then be switched so that the largest element is the pivot element. This is called partial pivoting. If the pivot element a(l) ll is small relative to the entries in the same column that is below a(l) ll the diagonal, select the element in the same column that has the largest absolute value; Here we determine smallest p Ø l such that pl | = max and perform Rl ¡ Rp Note: If columns as well as rows are searched for the largest element and then switched, the procedure is called complete pivoting. Complete pivoting is rarely used because switching columns changes the order of the xÕs and adds signiﬁcant complexity. Aside from avoiding division by zero, pivoting also minimizes round-oﬀerror. Scaled Partial Pivoting: When the magnitudes of the pivot elements are smaller than the magnitudes of the other elements in the row containing the pivot elements, the appropriate row interchange to place zeros in the ﬁrst column is determined by choosing the least integer p. Let ti = max1ÆjÆn |aij|. If ti ”= 0, select the row, Rp, p Ø i with max |aki| and perform the row interchange Ri ¡ Rp if i ”= p. The eﬀect of scaling is to ensure that the largest element in each row has a relative magnitude of 1 before the comparison for row interchange is performed. If we have ti = 0 for some i, then the system has no unique solution since all entries in the ith row are 0. Example 1.4.1 Use Gaussian Elimination with partial pivoting to ﬁnd the solution of linear system Example 1.4.2 Use Gaussian Elimination with partial pivoting to ﬁnd the solution of linear system Example 1.4.3 Applying scaled partial pivoting to the previous Illustration gives Solution: t1 = max{|30.00|, |591400|} = 591400, t2 = max{|5.291|, |6.130|} = 6.130. Consequently, and exchange Now apply Gaussian elimination to the new system produces the correct results: x1 = 10.00 and x2 = 1.000. ill-conditioned and well conditioned systems The system on the left has solution x = 2, y = 0 while the one on the right has solution x = 1, y = 1. The coeﬃcient matrix is called ill-conditioned because a small change in the constant coeﬃcients results in a large change in the solution. A condition number, deﬁned in terms of the norms of the matrix and its inverse, is used to measure the degree of ill-conditioning of a matrix (4004 for the above). An ill-conditioned problem is one in which a small change in any of the elements of the problem causes a large change in the solution of the problem. If a small change in any of the elements of the problem causes only a small change in the solution of the problem then it is a well-conditioned problem. The round-oﬀ errors eﬀectively change the elements of A and B slightly, and if the system is ill-conditioned, large changes(i.e., errors) can occur in the solution. In the presence of rounding errors, ill-conditioned systems are inherently diﬃcult to handle. When solving systems where round-oﬀ errors occur, one must avoid ill-conditioned systems whenever possible; this means that the usual row reduction algorithm must be modiﬁed. We now turn attention to a class of matrices for which Gaussian elimination can be performed eﬀectively without row interchanges."
  },
  {
    "index": 2,
    "title": "1.2 Matrix Decomposition",
    "content": "Diagonally Dominant Matrices Deﬁnition 1.4.1 The n ◊ n matrix A is said to be diagonally dominant when |aii| Ø |aij| holds for each i = 1, 2, ..., n. A diagonally dominant matrix is said to be strictly diagonally dominant when the |aii| > |aij| holds for each i = 1, 2, ..., n. Example 1.4.4 Consider the matrices A= V and B= The nonsymmetric matrix A is strictly diagonally do inant because |7| > |2| + |0|, |5| > |3| + |1|, and |6| > |0| + |5|. The symmetric matrix B is not strictly diagonally dominant because, for example, in the ﬁrst row the absolute value of the diagonal element is |6| < |4| + |3| = 7. Theorem 1.4.1 A strictly diagonally dominant matrix A is nonsingular. Moreover, in this case, Gaussian elimination can be performed on any linear system of the form Ax = b to obtain its unique solution without row or column interchanges, and the computations will be stable with respect to the growth of round-oﬀerrors. The next special class of matrices is called positive deﬁnite. Positive Deﬁnite Matrices Deﬁnition 1.4.2 A matrix A is positive deﬁnite if it is symmetric and if xtAx > 0 for every n-dimensional vector x ”= 0. Example 1.4.5 Show that is positive deﬁnite. Deﬁnition 1.4.3 A Leading Principal submatrix of a matrix A is matrix of the form WWWU akk XXXV for some 1 Æ k Æ n. Theorem 1.4.2 If the matrix A is positive deﬁnite, then all the eigen values of A are non-negative. Theorem 1.4.3 A symmetric matrix A is positive deﬁnite if and only if each of its leading principal submatrices has a positive determinant. Example 1.4.6 Show that matrix A is positive deﬁnite. A= Theorem 1.4.4 The symmetric matrix A is positive deﬁnite if and only if Gaussian elimination without row interchanges can be performed on the linear system Ax = b with all pivot elements positive. Moreover, in this case, the computations are stable with respect to the growth of round-oﬀerrors. Vector and Matrix Norms A norm is a real-valued function that provides a measure of the size or ”length” of multicomponent mathematical entities such as vectors and matrices Deﬁnition 1.5.1 A vector norm on Rn is a function, ||.|| from Rn into R with the following properties: i ||x|| Ø 0 for all x œ Rn, ii ||x|| = 0 if and only if x = 0 , iii ||-x|| = |-|||x|| for all - œ R and x œ Rn, iv ||x + y|| Æ ||x|| + ||y|| for all x, y œ Rn, Deﬁnition 1.5.2 The l1, l2 and lŒ norms for the vector x = (x1, x2, ..., xn)T as follows respectively. 2 (Euclidean Norm) iii ||x||Œ = max Example 1.5.1 Determine the l1, l2 and lŒ norm of the vector v = (≠5, 1, 3)T . Example 1.5.2 Find the shape of a unit circle, centred at (0,0) with respect to norms l1, l2 and lŒ Theorem 1.5.1 The Cauchy-Schwarz inequality, also known as the Cauchy-Bunyakovsky-Schwarz inequality, states that for all x = (x1, x2, ..., xn)T and y = (y1, y2, ..., yn)T , xiyi Deﬁnition 1.5.3 (Equivalent Norms) Let ||.||v1 and ||.||v2 be norms. We say that ||.||v1, ||.||v2 are equivalent, if there exist positive constants c1, c2 such that for all x œ Rn Theorem 1.5.2 ||.||Œ, ||.||2 and ||.||1 deﬁned on Rn are equivalent norms. i.e. the following inequalities holds Deﬁnition 1.5.4 A matrix norm on the set of all n ◊n matrices is a real-valued function, Î.Î, deﬁned on this set, satisfying for all n ◊n matrices A and B and all real numbers -: • ÎAÎ = 0 if and only if A is a zero matrix, Deﬁnition 1.5.5 (Induced Matrix) If Î.Îv is a vector norm deﬁned on Rn then the matrix norm induced by the vector norm Î.Îv is given by, sup sup One can compute the matrix norm induced by the vector norm using above deﬁnition. Alternatively, following theorems can be used to compute the matrix norms induced by the vector norms. Theorem 1.5.3 If A = (ai,j)1<i,j<n œ Rn◊n, then the matrix norm induced by • ÎAÎŒ Norm: ÎAÎŒ = max |ai,j| ≠Maximum row sum • ÎAÎ1 Norm: ÎAÎ1 = max |ai,j| ≠Maximum column sum Deﬁnition 1.5.6 The set of all eigen values of matrix A is called the spectrum of A and denoted by ‡(A) = {⁄i |Av = ⁄v ; v œ Rn, ⁄ is an eigen value of A} The maximum absolute value of eigen values of A is called the spectral radius of A and denoted by, ﬂ(A) = max Theorem 1.5.4 If A = (ai,j)1<i,j<n œ Rn◊n, then the matrix norm induced by ÎAÎ2 Norm: where, ﬂ(A) = max(⁄)= Spectral radius of A and ⁄ is an eigen value of A Theorem 1.5.5 For any matrix norm Î.Îm induced by the vector norm Î.Îv for all A œ Rn◊n Example 1.5.3 Determine ÎAÎŒ, ÎAÎ1 and ÎAÎ2 Deﬁnition 1.5.7 A square matrix An◊n is said to be convergent to B if lim Theorem 1.5.6 For any Square matrix A the following statements are equivalent • A is convergent to 0 i.e. limkæŒ Ak = 0 • limkæŒ ÎAÎk m = 0 for some matrix norm Î.Îm LU Decomposition LU decomposition of a matrix is the factorization of a given square matrix into two triangular matrices, one upper triangular matrix and one lower triangular matrix, such that the product of these two matrices gives the original matrix. It was introduced by Alan Turing in 1948. This method of factorizing a matrix as a product of two triangular matrices has various applications such as a solution of a system of equations, which itself is an integral part of many applications such as ﬁnding current in a circuit and solution of discrete dynamical system problems; ﬁnding the inverse of a matrix and ﬁnding the determinant of the matrix. Basically, the LU decomposition method comes in handy whenever it is possible to model the problem to be solved into matrix form. Conversion to the matrix form and solving with triangular matrices makes it easy to do calculations in the process of ﬁnding the solution. Suppose that A has been factored into the triangular form where L is lower triangular and U is upper triangular Note: L is lower triangular. This means that all entries above the main diagonal are zero. U is upper triangular. This means that all entries below the main diagonal are zero. Using LU Decomposition to Solve Linear Systems Suppose we have A = LU and want to solve the system AX = LUX =. B. • Step 1: Set W = (u, v, w) = UX • Step 2: Solve the system LW = B . This should be simple by forward substitution since L is lower triangular. Suppose the solution to LW = B is W0. • Step 3: Now solve the system UX = W0. This should be easy by backward substitution, since U is upper triangular. The solution to this system is the solution to the original system. We can think of this as using the matrix L to perform row operations on the matrix U in order to solve the system. Example 1.5.4 Consider the linear system: An LU decomposition for the associated matrix A is: • Step 1: set W= • Step 2 Solve the system LW = V now by substituting we get u = 1, v = 3 and w = ≠11 • Step 3: Solve the systen UX = W0. V Back substitution gives z = ≠11, y = 3 and x = ≠6. Then X= Finding L and U with no pivoting • Method 01 Theorem 1.5.7 If Gaussian elimination can be performed on the linear system AX = B without row interchanges, then the matrix A can be factored into the product of a lower triangular matrix L and and an upper-triangular matrix U, that is, A = LU, where mji = • Method 2 - For i = 1, 2, ..., n set lii = 1 or uii = 1 - For j = 2, 3, ..., n set - For i = 2, 3, ..., n ≠1 ∗liiuii = aii ≠ likuki ∗For j = i + 1, ..., n · uij = 1 lii aij ≠ likukj · lji = 1 uii aji ≠ ljkuki and - lnnun = ann ≠ lnkukn Notice that for the LU decomposition implementation of Gauss elimination, the L matrix has 1's on the di- agonal. This is formally referred to as a Doolittle decomposition or factorization. An alternative approach involves a U matrix with 1's on the diagonal. This is called Crout decomposition The LU decomposition can fail when the top-left entry in the matrix A is zero or very small compared to other entries. Pivoting is a strategy to mitigate this problem by rearranging the rows and/or columns of A to put a larger element in the top-left position. There are many diﬀerent pivoting algorithms. LUP Decomposition The LU decomposition with partial pivoting (LUP) of an n ◊n matrix A is the triple of matrices L, U, and P such that: • L is an n ◊n lower-triangular matrix with all diagonal entries equal to 1 • U is an n ◊n upper-triangular matrix • P is an n ◊n permutation matrix. The properties of the LUP decomposition are: • The permutation matrix P acts to permute the rows of A • This attempts to put large entries in the top-left position of A and each sub-matrix in the recursion, to avoid needing to divide by a small or zero element. item LUP decomposition always exists for a matrix A • The LUP decomposition of a matrix A is not unique. • The LUP decomposition provides a more robust method of solving linear systems than LU decomposition without pivoting, and it is approximately the same cost. The LUP decomposition for a matrix A allows us to solve the linear system Ax = b by ﬁrst applying P and then using the LU solver. In equations we start by taking Ax = b and multiplying both sides by P , giving PAx = Pb LUx = Pb Just as there are diﬀerent LU decomposition algorithms, there are also diﬀerent algorithms to ﬁnd a LUP decomposition. Here we use therecursive leading-row-column LUP algorithm. This algorithm is a recursive method for ﬁnding L, U, and P so that PA = LU. It consists of the following steps. • First choose i so that row i in A has the largest absolute ﬁrst entry. That is, |Ai1| Ø |Aj1| for all j. Let P1 be the permutation matrix that pivots (shifts) row i to the ﬁrst row, and leaves all other rows in order • Write ¯A to denote the pivoted A matrix, so ¯A = P1A. • Let P2 be a permutation matrix that leaves the ﬁrst row where it is, but permutes all other rows. We can write P2 as where P22 is an (n ≠1) ◊(n ≠1) permutation matrix. • Factorize the (unknown) full permutation matrix P as the product of P2 and P1, so P = P2P1. This means that PA = P2P1A = P2 ¯A, which ﬁrst shifts row i of A to the top, and then permutes the remaining rows. This is a completely general permutation matrix P, but this factorization is key to enabling a recursive algorithm. • Using the factorization P = P2P1 , now write the LUP factorization in block form as • Equating the entries in the above matrices gives the equations • Substituting the ﬁrst three equations above into the last one and rearranging gives • Solve for the ﬁrst rows and columns of L and U with the above equations to give Example 1.5.5 Find the LU factorization with partial pivoting of the matrix Tridiagonal Systems of Equations Tridiagonal matrix is a square matrix that has nonzero elements only on the diagonal plus or minus one column. Crout factorization is used to compute L and U. Since A is tridiagonal,L and U also have the tridiagonal form. The Crout Factorization Algorithm can be applied whenever lii ”= 0 for each i = 1, 2, ..., n WWWWWU. lnn XXXXXV WWWWWU XXXXXV. - Set l11u11 = a11 or u12 = a12 - For i = 2, 3, ..., n ≠1 ∗lii = aii ≠li,i≠1ui≠1,i lii ∗ln,n≠1 = an,n≠1, lnn = ann ≠ln,n≠1un≠1,n Cholesky Decomposition Corollary 1.5.1 The matrix A is positive deﬁnite if and only if A can be factored in the form LLT , where L is lower triangular with non-zero diagonal entries. The above factorization of A is known as Cholesky Decomposition A = LLT That is the resulting triangular factors are the transpose of each other. The terms of A = LLT can be multiplied out and set equal to each other. The result can be expressed for kth row simply by lki = aki ≠ lijIkj lii for i = 1, 2, ..., k ≠1 and lkk = Ùakk ≠ Example 1.5.6 Apply Cholesky decomposition to the symmetric matrix."
  },
  {
    "index": 3,
    "title": "2. Numerical Solutions of Nonlinear Systems",
    "content": "Chapter II Numerical Solutions of Nonlinear System of Equations Fixed Points for Functions of Several Variables A system of nonlinear equations has the form where each function fi can be thought of as mapping a vector x = (x1, x2, ..., xn)t of the n-dimensional space Rn into the real line R. This system of n nonlinear equations in n unknowns can also be represented by deﬁning a function F mapping Rn into Rn as If vector notation is used to represent the variables x1, x2, ..., xn, then system ( assumes the form If vector notation is used to represent the variables x1, x2, ..., xn, then system 2.1 assumes the form The functions f1, f2, ..., fn are called the coordinate functions of F. Example 2.1.1 Place the 3 ◊3 nonlinear system 3x1 ≠cos(x2x3) ≠1 1 ≠81(x2 + 0.1)2 + sin x3 + 1.06 = 0, in the form 2.2. Deﬁne the three coordinate functions f1, f2, and f3 from R3 to R as f1(x1, x2, x3) = 3x1 ≠cos(x2x3) ≠1 1 ≠81(x2 + 0.1)2 + sin x3 + 1.06, Then deﬁne F from R3 æR3 by. 3x1 ≠cos(x2x3) ≠1 1 ≠81(x2 + 0.1)2 + sin x3 + 1.06, e≠x1x2 + 20x3 + 10ﬁ≠3 Theorem 2.1.1 Let f be a function from D µ Rn into R and x0 œ D. Suppose that all the partial derivatives of f exist and constants ” > 0 and K > 0 exist so that whenever Îx ≠x0Î < ” and x œ D, we have ---- Æ K. for each j = 1, 2, ..., n. Then f is continuous at x0. Fixed Points in Rn Deﬁnition 2.1.1 A function G from D µ Rn into Rn has a ﬁxed point at p œ D if G(p) = p The following theorem explains the Fixed-Point Theorem to the n-dimensional case. This theorem is a special case of the Contraction Mapping Theorem. Theorem 2.1.2 Let D = {(x1, x2, ..., xn)t|ai Æ xi Æ bi, for each i = 1, 2, ..., n} for some collection of constants a1, a2, ..., an and b1, b2, ..., bn. Suppose G is a continuous function from D µ Rn into Rn with the property that G(x) œ D whenever x œ D. Then G has a ﬁxed point in D. Moreover, suppose that all the component functions of G have continuous partial derivatives and a constant K < 1 exists with n , whenever x œ D, for each j = 1, 2, ..., n and each component function gi. Then the sequence {x(k)}Œ k=0 deﬁned by an arbitrarily selected x(0) in D and generated by x(k) = G(x(k≠1)), for each k Ø 1 converges to the unique ﬁxed point p œ D Example 2.1.2 Place the nonlinear system 3x1 ≠cos(x2x3) ≠1 1 ≠81(x2 + 0.1)2 + sin x3 + 1.06 = 0, in a ﬁxed-point form x = G(x) by solving the ith equation for xi , show that there is a unique solution on D = {(x1, x2, x3)t| ≠1 Æ xi Æ 1, for each i = 1, 2, 3}. and iterate starting with x(0) = (0.1, 0.1, ≠0.1)t. Solution: Solving the ith equation for xi gives the ﬁxed-point problem, 3 cos(x2x3) + 1 1 + sin x3 + 1.06 ≠0.1, Let G : R3 æ R3 be deﬁned by G(x) = (g1(x), g2(x), g3(x))t, where 3 cos(x2x3) + 1 1 + sin x3 + 1.06 ≠0.1, Theorems 2.1.1 and 2.1.2 show that there is a unique solution on D = {(x1, x2, x3)t| ≠1 Æ xi Æ 1, for each i = 1, 2, 3}. Now for x = (x1, x2, x3)t in D, 3| cos(x2x3)| + 1 1 + sin x3 + 1.06 ≠0.1| Æ 1 1 + sin 1 + 1.06 ≠0.1 < 0.09, and So we have, for each i = 1, 2, 3, Thus G(x) œ D whenever x œ D. Finding bounds for the partial derivatives on D gives as well as, 3|x3|| sin x2x3| Æ 1 3 sin 1 < 0.281, 3|x2|| sin x2x3| Æ 1 3sin1 < 0.281, 1 + sin x3 + 1.06 | cos x3| 1 + sin x3 + 1.06 20 < 0.14, and The partial derivatives of g1, g2, and g3 are all bounded on D, so Theorem 2.1.1 implies that these functions are continuous on D. Consequently, G is continuous on D. Moreover, for every x œ D, ---- Æ 0.281 for each i = 1, 2, 3 and and the condition in the second part of Theorem 2.1.2 holds with K = 3(0.281) = 0.843. In the same manner it can also be shown that ---- is continuous on D for each i = 1, 2, 3 and j = 1, 2, 3. Consequently, G has a unique ﬁxed point in D, and the nonlinear system has a solution in D. To approximate the ﬁxed point p, we choose x(0) = (0.1, 0.1, ≠0.1)t. The sequence of vectors generated by 3 cos )2 + sin x(k≠1) converges to the unique solution. The results in following Table were generated until The results in Table 10.1 were generated until We could use the error bound with K = 0.843. This gives which does not indicate the true accuracy of x(5). The actual solution is Accelerating Convergence One way to accelerate convergence of the ﬁxed-point iteration is to use the latest estimates x(k) instead of x(k≠1) to compute x(k) , as in the Gauss-Seidel method for linear systems. The component equations for the problem in the example then become 3 cos 1 )2 + sin x(k≠1) With x(0) = (0.1, 0.1, ≠0.1)t, the results of these calculations are listed in the following Table Practice Exercises 2.1.1 • Show that the function F : R3 æ R3 deﬁned by F(x1, x2, x3) = (x1 + 2x3, x1 cos x2, x2 is a continuous at each point of R3. • The nonlinear system can be transformed into the ﬁxed-point problem - Use Theorem 2.1.2 to show that G = (g1, g2)t mapping D µ R2 into R2 has a unique ﬁxed point in - Apply functional iteration to approximate the solution. - Does the Gauss-Seidel method accelerate convergence? Newton's Method In the last section we transformed non linear system of equations into a convergent ﬁxed-point problem by algebraically solving the equations for the each variables x1, x2, ...xn. It is, however, unusual to be able to ﬁnd an explicit representation for all the variables. In this section, we consider an algorithmic procedure to perform the transformation in a more general situation. To construct the algorithm that led to an appropriate ﬁxed-point method in the one- dimensional case, we found a function „ with the property that gives quadratic convergence to the ﬁxed point p of the function g. From this condition Newton's method evolved by choosing „(x) = f Õ(x), assuming that f Õ(x) ”= 0. A similar approach in the n-dimensional case involves a matrix. WWWU akk(x) XXXV where each of the entries aij(x) is a function from Rn into R. This requires that A(x) be found so that gives quadratic convergence to the solution of F(x) = 0, assuming that A(x) is nonsingular at the ﬁxed point p of G. Theorem 2.2.1 Let p be a solution of G(x) = x. Suppose a number ” > 0 exists with is continuous on N” = {x|Îx ≠pÎ < ”}, for each i = 1, 2,...,n and j = 1,2,...,n; is continuous, and ˆxjk ---- Æ M for some constant M , whenever x œ N”, for each i = 1, 2, ..., n, j = 1, 2, ..., n, and k = 1, 2, ..., n; = 0 for each i = 1, 2, ..., n and k = 1, 2, ..., n Then a number ˆ” Æ ” exists such that the sequence generated by x(k) = G(x(k≠1)) converges quadratically to p for any choice of x(0), provided that .. < ˆ”. Moreover, Œ, for each k Ø 1. To apply Theorem 2.2.1, suppose that A(x) is an n◊n matrix of functions from Rn into R in the form of above matric form. Assume, moreover, that A(x) is nonsingular near a solution p of F(x) = 0, and let bij(x) denote the entry of A(x)≠1 in the ith row and jth column. For G(x) = x ≠A(x)≠1F(x), we have gi(x) = xi ≠ bij(x)fj(x). bij(x)ˆfj(x) + fj(x)ˆbij(x) bij(x)ˆfj(x) + fj(x)ˆbij(x) Theorem 2.2.1 implies that we need ˆgi(p) = 0, for each i = 1, 2, ..., n and k = 1, 2, ..., n. This means that for bij(p)ˆfj(p) bij(p)ˆfj(p) when k ”= i, bij(p)ˆfj(p) bij(p)ˆfj(p) The Jacobian Matrix Deﬁne the matrix J(x) by WWWWWWWWU XXXXXXXXV. Now by conditions 2.3 and 2.4 require that A(p)≠1J(p) = I, the identity matrix, so A(p) = J(p). An appropriate choice for A(x) is, consequently, A(x) = J(x) since this satisﬁes condition III in Theorem2.2.1. The function G is deﬁned by and the functional iteration procedure evolves from selecting x(0) and generating, for kgeq1, This is called Newton's method for nonlinear systems, and it is generally expected to give quadratic convergence, provided that a suﬃciently accurate starting value is known and that J(p)≠1 exists. The matrix J(x) is called the Jacobian matrix and has a number of applications in analysis. Example 2.2.1 Apply Newton's method to this problem with x(0) = (0.1, 0.1, ≠0.1)t 3x1 ≠cos(x2x3) ≠1 1 ≠81(x2 + 0.1)2 + sin x3 + 1.06 = 0, where, f1(x1, x2, x3) = 3x1 ≠cos(x2x3) ≠1 1 ≠81(x2 + 0.1)2 + sin x3 + 1.06, The Jacobian matrix J(x) for this system is x3 sin x2x3 x2 sin x2x3 cos(x3) Let x(0) = (0.1, 0.1, ≠0.1)t, then F(x0) = (≠0.199995, ≠2.269833417, 8.462025346) and, Solving the linear system, J(x(0))y(0) = F(x(0)) gives and Continuing for k = 2, 3, ..., we have where, Thus, at the kth step, the linear system J(x(k≠1))y(k≠1) = F(x(k≠1)) must be solved, where sin x(k≠1) sin x(k≠1) cos x(k≠1) Hence, WWU ≠cos + 0.1)2 + sin x(k≠1) XXV The results using this iterative procedure are shown in Table The previous example illustrates that Newton's method can converge very rapidly once a good approximation is obtained that is near the true solution"
  },
  {
    "index": 4,
    "title": "3. Interpolation",
    "content": "Chapter III Interpolation. Cubic Spline interpolation In cubic spline interpolation, the interpolation function is a set of piecewise cubic functions. Speciﬁcally, we assume that the points (xi, yi) and (xi+1, yi+1) are joined by a cubic polynomial Si(x) = aix3 + bix2 + cix + di that is valid for xi ≤x ≤xi+1 for i = 1, 2, ..., n -1. To ﬁnd the interpolation function, we must ﬁrst determine the coeﬃcients ai, bi, ci, di for each of the cubic functions. For n points, there are n -1 cubic functions to ﬁnd, and each cubic function requires four coeﬃcients. Therefore we have a total of 4(n -1) unknowns, and so we need 4(n -1) independent equations to ﬁnd all the coeﬃcients. Deﬁnition 3.0.1 Given a function f deﬁned on [a, b] and a set of nodes a = x0 < x1 < ... < xn = b, a cubic spline interpolant S for f is a function that satisﬁes the following conditions: a). S(x) is a cubic polynomial, denoted Sj(x), on the subinterval [xj, xj+1] for each j = 0, 1, ..., n -1; b). (interpolating data) Sj(xj) = f(xj) and Sj(xj+1) = f(xj+1) for each j = 0, 1, ..., n -1; c). (continuity at interior points) Sj+1(xj+1) = Sj(xj+1) for each j = 0, 1, ..., n -2; (Implied by (b).) d). (continuous slope at interior points) S' j(xj+1) for each j = 0, 1, ..., n -2; e). (continuous curvature at interior points) S'' j (xj+1) for each j = 0, 1, ..., n -2; f). One of the following sets of boundary conditions is satisﬁed: - S''(x0) = S''(xn) = 0(natural (or free) boundary); - S'(x0) = f '(x0) and S'(xn) = f '(xn) (clamped boundary). Although cubic splines are deﬁned with other boundary conditions, the conditions given in (f) are suf- ﬁcient for our purposes. When the free boundary conditions occur, the spline is called a natural spline, and its graph approximates the shape that a long ﬂexible rod would assume if forced to go through the data points (x0, f(x0)), (x1, f(x1)), ..., (xn, f(xn)). In general, clamped boundary conditions lead to more accurate approximations because they include more information about the function. However, for this type of boundary condition to hold, it is necessary to have either the values of the derivative at the endpoints or an accurate approximation to those values. Construct a natural cubic spline that passes through the points (1, 2), (2, 3), and (3, 5). Solution This spline consists of two cubics.The nodes are x0 = 1, x1 = 2, x2 = 3 and This spline consists of two cubic The ﬁrst for the interval [1, 2], denoted and the other for [2, 3], denoted There are 8 constants to be determined, which requires 8 equations. The cubic splines must agree with the data at the nodes: and for j = 0, 1. Hence we have for equations, Now as the ﬁrst derivatives at the interior nodes must be equal and the second derivatives at the interior nodes must be equal: 1(2) and S'' The ﬁnal two come from the natural boundary conditions: Solving these equations [2.8-2.15], for a0, b0, c0, d0, a1, b1, c1, d1 we have Therefore, the cubic polynomial S for the given data set is Construction of a Cubic Spline As the preceding example demonstrates, a spline deﬁned on an interval that is divided into n subintervals will require determining 4n constants. To construct the cubic spline interpolant for a given function f , the conditions in the deﬁnition are applied to the cubic polynomials for each j = 0, 1, ..., n -1. Since Sj(xj) = aj = f(xj), condition (c) can be applied to obtain for each j = 0, 1, ..., n -2 The terms xj+1 -xj are used repeatedly in this development, so it is convenient to introduce the simpler notation for each j = 0, 1, ..., n -1 we also deﬁne an = f(xn), then the equation aj+1 = aj + bjhj + cjh2 j + djh3 j holds for each j = 0, 1, ..., n -1. In a similar manner, deﬁne bn = S'(xn) and observe that implies S' j(xj) = bj, for each j = 0, 1, ..., n -1. Applying condition (d) gives bj+1 = bj + 2cjhj + 3djh2 j, for each j = 0, 1, ..., n -1. Another relationship between the coeﬃcients of Sj is obtained by deﬁning cn = S''(xn)/2 and applying condition (e). Then, for each j = 0, 1, ..., n -1, cj+1 = cj + 3djhj. Solving for dj in the above Eq 3.11 and substituting this value into Eqs. 3.9 and 3.10 gives, for each j = 0, 1, ..., n -1, the new equations aj+1 = aj + bjhj + h2 and The ﬁnal relationship involving the coeﬃcients is obtained by solving the appropriate equation in the last form of equation 3.12, ﬁrst for bj, and then, with a reduction of the index, for bj-1. This gives Substituting these values into the equation derived from Eq 3.13, with the index reduced by one, gives the linear system of equations hj-1cj-1 + 2(hj-1 + hj)cj + hjcj+1 = 3 for each j = 1, 2, ..., n -1. This system involves only the cjn j=0 as unknowns. The values of {hj}n1 and {aj}n j=0 are given, respectively, by the spacing of the nodes {xj}n j=0 and the values of f at the nodes.So once the values of {cj}n j=0 are determined, it is a simple matter to ﬁnd the remainder of the constants {bj}n-1 j=0 from Eq. 3.14 and {dj}n-1 j=0 from Eq.3.11. Then we can construct the cubic polynomials Theorem 3.0.1 If f is deﬁned at a = x0 < x1 < ... < xn = b, then f has a unique natural spline interpolant S on the nodes x0, x1, ..., xn; that is, a spline interpolant that satisﬁes the natural boundary conditions S''(a) = 0 and S''(b) = 0. Proof 3.0.1 The boundary conditions in this case imply that cn = S''(xn)/2 = 0 and that so c0 = 0. The two equations c0 = 0 and cn = 0 together with the equations in 3.13 produce a linear system described by the vector equation Ax = b, where A is the (n + 1) × (n + 1) matrix The matrix A is strictly diagonally dominant, that is, in each row the magnitude of the diagonal entry exceeds the sum of the magnitudes of all the other entries in the row. Hence the proof. Theorem 3.0.2 If f is deﬁned at a = x0 < x1 < ... < xn = b and diﬀerentiable at a and b,then f has a unique clamped spline interpolant S on the nodes x0, x1, . . , xn; that is, a spline interpolant that satisﬁes the clamped boundary conditions S'(a) = f '(a) and S'(b) = f '(b). Proof 3.0.2 Since f '(a) = S'(a) = S'(x0) = b0, Eq. 3.14 with j = 0 implies 3 (2c0 + c1). Consequently, Similarly, so Eq. 3.14 with j = n -1 implies that and Equations 3.13 together with the equations and determine the linear system Ax = b, where This matrix A is also strictly diagonally dominant. Therefore, the linear system has a unique solution for Example 3.0.1 Use the data points (0, 1), (1, e), (2, e2), and (3, e3) to form a clamped spline S(x) that approximates f(x) = ex on the interval [0, 3] . since f '(x) = ex ,so f '(0) = 1 and f '(3) = e3 we have n = 3, h0 = h1 = h2 = 1, a0 = 1, a1 = e, a2 = e2, and a3 = e3 . This together with the information that f '(0) = 1 and f '(3) = e3 gives the the matrix A and the vectors b and x with the forms The vector-matrix equation Ax = b is equivalent to the system of equations Solving this system simultaneously for c0, c1, c2 and c3 gives, to 5 decimal places Solving for the remaining constants gives and This gives the clamped cubic spline Error An error-bound formula for the cubic spline with clamped boundary conditions is given in following theorem. Theorem 3.0.3 Let f ∈C4[a, b] with maxa≤b|f (4)(x)| = M. If S is the unique clamped cubic spline interpolant to f with respect to the nodes a = x0 < x1 < ... < xn = b,then for all x ∈[a, b], max A fourth-order error-bound result also holds in the case of natural boundary conditions, but it is more diﬃcult to express. Example 3.0.2 Let's compute the error bound for the previous example using the Theorem. Since f(x) = e4, f 4(x) = ex.Alsoex is an increasing function. Therefore maximum occurs at the right end point. Thus M = max The nodes are equally spaced. Therefore, max(xj+1 -xj)4 = 1. Thus, max"
  },
  {
    "index": 5,
    "title": "4. Optimization",
    "content": "Chapter IV Optimization. Introduction - Optimization is the term often used for minimizing or maximizing a function. - Geometrically, the maximum or minimum occurs at the turning point or at the end points of a function. - Mathematically, the derivative of function is zero at the turning point. Moreover, the second deriva- tive, f Õ(x), indicates whether the optimum is a minimum or a maximum: if f ÕÕ(x) < 0, the point is a maximum; if f ÕÕ(x) > 0, the point is a minimum. - In one dimensional optimization problem, we need to ﬁnd x that corresponds the derivative f Õ(x) is equal to zero. - In engineering, the quantity that we wish to optimize, f(x), called the merit function or objective function, and the quantities that we are free to adjust, x, known as the design variables. - There are two main optimizations: ∗Constrained optimization : restrictions or constraints are placed on the design variables ∗Unconstrained optimization : no restrictions are placed on the design variables - Sometimes both local and global optima can occur in optimization as shown in ﬁgure. Such cases are called multimodal. If function has single optimum (i.e. maximum or minumum), then it is unimodal. - In almost all instances, we will be interested in ﬁnding the absolute highest or lowest value of a function. Thus, we must take care that we do not mistake a local result for the global optimum. Multidimensional Unconstrained Optimization Example 5.3 f(x, y) = 1 -x2 -y2 has a maximum at (0, 0) since @f and Figure 5.7 • The derivative of function f(x, y) is maximized in the direction of gradient and it is minimized in the opposite direction of gradient. • The gradient of f(x, y) is • An obvious strategy for climbing a hill would be to determine the maximum slope at your starting position and then start walking in that direction. • Since the slope is changed point to point you could walk a short distance along the gradient direction, stop and reevaluate the gradient and walk another short distance. By repeating the process you would eventually get to the top of the hill. • Using this stratergy, the following method was developed. Steepest Ascent Method To determine the maximum of f(x, y): • Start from (x0, y0) evaluate gradient at (x0, y0). • Search along the direction of the gradient, h0, until we ﬁnd a maximum. - Start from (x0, y0), the direction of the gradient can be expressed as Dep of Math, UoM - Evaluate f(x, y) in direction h0. - Set g0(h0) = 0 and ﬁnd h0. • The process is then repeated. Figure 5.8 • Note that to ﬁnd the minimum of f(x, y), follow the above steps using -rf(x, y). This method is called as steepest descent method. Example 5.4 Maximize the following function: using initial guesses, x = -1 and y = 1. Figure 5.9 SOLUTION:. Now let us implement steepest ascent. Note that Dep of Math, UoM • Initial approximation: (x0, y0) = (-1, 1) • 1st Iteration: • 2nd Iteration: • 3rd Iteration: Figure 5.10 Dep of Math, UoM Constrained Optimization • Constraint optimization is the process of optimizing an objective function with respect to some variables in the presence of constraints on those variables. • General constrained minimization problem may be written as follows: min subject to for i = 1, . . , n Equality constraints for j = 1, . . , m Inequality constraints Linear Programming • The basic linear programming problem consists of two major parts: - a linear objective function z = f(x) = a1x1 + a2x2 + · · · + anxn - a set of constraints (linear ineaqualities) ai1x1 + ai2 + · · · + ainxn bi ai1x1 + ai2 + · · · + ainxn ≥bi Example 5.5 Energy Savers, Inc., produces heaters of types S and L. The wholesale price is $40 per heater for S and $88 for L. Two time constraints result from the use of two machines M1 and M2. On M1 one needs 2 min for an S heater and 8 min for an L heater. On M2 one needs 5 min for an S heater and 2 min for an L heater. Determine production ﬁgures x1 and x2 for S and L, respectively (number of heaters produced per hour), so that the hourly revenue is maximum. SOLUTION:. • The objective function (to be maximized) • Four constraints 2x1 + 8x2 60 (time on machine M1) 5x1 + 2x2 60 (time on machine M2) • Since this problem has limited number of varaibles, x1, x2, the solution can be approxi- mated by graphically. Dep of Math, UoM Figure 5.11 Graphical solution of a linear programming problem • The optimal solution is obtained by moving the line of constant revenue (0) up as much as possible without leaving the feasibility region completely. • Obviously, this optimum is reached when that line passes through B, the intersection (10, 5) of (1) and (2). We see that the optimal revenue zmax = (40)(10) + (88)(5) = $840 1References: (i) Numerical Methods for Engineers, Steven C. Chapra, Raymond P. Canale Dep of Math, UoM #Sie"
  },
  {
    "index": 6,
    "title": "Initial Value Problems",
    "content": "MA3024 Numerical Methods Notes (IVPs) Melanka Saroad Wedige July 2024 Introduction Consider the motion of a pendulum. For sufficiently small θ values, the motion is governed by the following differential equation. The equation gives us information about the function of θ(t) which is the vertical angle formed by the string at time t after it has begun motion. Information about the motion of the pendulum at the beginning includes the angle at which the pendulum was released from rest (initial angle) θ(0) and the initial speed of the pendulum theta'(0). We call these the initial values. Suppose, Then, together is called an initial value problem (IVP). This particular example is easily solved by analyt- ical methods. However, the vast majority of IVPs are not analytically solvable. The goal of these notes is to do a basic exploration on numerical methods to approximate solutions to IVPs. Elementary Theory of Initial Value Problems. Existence and Uniqueness of solutions to IVPs Definition 1 (Lipschitz functions) A function f(t, y) is said to satisfy a Lipschitz condition in the variable y on a set D ⊂R2 if a constant L > 0 exists with whenever (t, y1) and (t, y2) are in D. The constant L is called a Lipschitz constant for f. Example 1 The function f(t, y) = t|y| is Lipschitz on D = [1, 2] × [-3, 4] with Lipschitz constant 2. Since, Definition 2 (Convex sets) A set D ⊂R2 is said to be convex if whenever (t1, y1) and (t2, y2) belong to D, then ((1 -λ)t1 + λt2, (1 -λ)y1 + λy2) also belongs to D for every λ ∈[0, 1]. Theorem 1 Suppose that f(t, y) is defined on a convex set D ⊂R2. If a constant L > 0 exists with for all (t, y) ∈D. Then f satisfies a Lipschitz condition on D in variable y with Lipschitz constant Theorem 2 (Existence and uniqueness) Suppose D = [a, b] × R. Let f(t, y) be a continuous function on D. If f satisfies a Lipschitz condition on D in variable y, then the IVP has a unique solution y(t) for a ≤t ≤b. Example 2 Consider the IVP y' = 1 + t sin ty, 0 ≤t ≤2, y(0) = 0 Then consider the convex set D = [1, 2] × R and the function f(t, y) = 1 + tsin(ty). Since = |t2 cos ty|≤4, f(t, y) is Lipschitz on D in the variable y with Lipschitz constant 4 by theorem 1. Then by theorem 2, the IVP has a unique solution. Well-Posed problems Since we are actually trying to find numerical approximations to IVPs, it is important to know how the solutions will react to rounding off errors. In particular, how well the IVP is immune from large changes in the solution due to small changes in the IVP. Definition 3 The IVP, is said to be a well-posed problem if, 1. A unique solution y(t) exists to the problem. 2. There is a constant ϵ0 > 0 and k > 0 such that for any ϵ ∈(0, ϵ0), whenever δ(t) continuous with |δ(t)|< ϵ for t ∈[a, b], and when δ0 < ϵ, the IVP, has a unique solution z(t) that satisfies for all t ∈[a, b]. The idea is that small perturbations in the differential equation and initial value results in a a slight change in the solution that could be bounded proportional to the perturbations in the IVP. Theorem 3 (Well-posedness and Lipschitz) Suppose D = [a, b] × R. If f is continuous and satisfies a Lipschitz condition in the variable y on the set D, then the IVP is well-posed. Example 3 The IVP is well-posed on D = [0, 2] × R, by checking the Lipschitz condition. Remark 1 Before trying out any numerical approximations for any IVP, one should check whether it is well-posed. In most cases, checking the Lipschitz condition would suffice. However, there may be cases of well-posed IVPs that do not conform with the Lipschitz condition, hence in case of Lipschitz failure will need to verfiy against the definition for well-posed problems. Euler's Method The most basic numerical method to approximate solutions to a well-posed IVP of the form Euler's method does not give a continuous approximation to the IVP, instead will give approx- imations to y at certain t-values in the interval [a, b] called mesh points. The approximations between mesh points could be found by interpolation. We will usually pick the mesh points to be equidistributed within [a, b]. Mesh points on [a, b] Choose a positive integer N. Define the step size h = (b-a) . Then we define a sequence of N + 1 mesh points a = t0 < t1 < t2 < · · · < tN = b as follows, The mesh points will have an equal spacing of h on [a, b] i.e. ti+1 -ti = h. Derivation of Euler's method We will use Taylor's theorem on y(t) that we assume to be twice differentiable. By first order Taylor approximation we have, for some ξi ∈(ti, ti+1). For small enough h, the h2 term is negligible. So by dropping the 2nd order error term we have Now we approximate wi ≈y(ti) recursively as follows, wi+1 = wi + hf(ti, wi), for each i = 0, 1, · · · , N -1 The recursive formula is called the difference equation associated with the Euler method. Example 4 (Euler's method) We will use Euler's method to approximate the solution at t = 2 to the following IVP, We will use N = 4, hence h = 0.5 and f(t, y) = y -t2 + 1. So, Hence, y(2) ≈w4 = 4.4375. The actual closed form solution to the IVP is y(t) = (t + 1)2 -0.5et. The following plot shows the graph of the actual solution and it's Euler's method solutions at t = 0, 0.5, 1.0, 1.5, 2.0 Error bounds for Euler's method We will state error bounds for the Euler's method approximation for the IVP given by eq. (3) and the mesh points eq. (4) as two theorems. Theorem 4 (Theoretical error bound - Euler's method) If f(t, y) in eq. (3) satisfies the Lip- schitz function with Lipschitz constant L > 0 and the unique solution y(t) to the IVP satisfies |y''(t)|≤M for some M > 0 then for each i = 0, 1, · · · , N Note that the error bound is proportional to h, i.e. the first power of h. Hence, we say that the Euler method has an error of order 1. Higher the order the better. Worth mentioning that the given bound may be much larger than the actual error. The following tabulation of results obtained by applying Euler method in example 4 with h = 0.1 shows this fact, specially as i increases. Actual Error Error Bound In actual computations we should factor in the precision of the numbers used. As h becomes smaller and smaller, the rounding errors become more significant with respect to h. Suppose at each step of the algorithm, the rounding-off error is bounded by δ, and the values ui values calculated has an error (from the theoretical Euler approximation) ui -wi = δi such that |δi|< δ. ui+1 = ui + hf(ti, ui) + δi+1, for each i = 0, 1, · · · , N -1 Theorem 5 (Computational error bound - Euler's method) Based on the definitions and notation introduced so far, for each i = 0, 1, · · · , N Note that, lim Hence error grows with decreasing h for sufficiently small h. Optimizing h we get that minimal error is obtained when, Remark 2 Note that Euler's method was derived from first order Taylor approximation. Simi- lar methods derived from higher order Taylor approximations give much better approximations for solutions to IVPs. Runge-Kutta Methods Runge-Kutta methods are based on approximating solutions to IVPs from higher order Taylor approximations. Consider the following IVP, (3 revisited) The second order Taylor approximation of y(t) is as follows, Now since y'(t) = f(t, y(t)), Note that this approximation requires the computation of the derivatives of f with respect to t. Computing derivatives are computationally expensive and also f may not have derivatives of all orders everywhere on the domain. Runge-Kutta methods focuses on eliminating these derivative terms by replacing them by function terms f evaluated at carefully selected (t, y) points. Midpoint method To elaborate on what we have said above we have the following approximation, Simply approximating it using the midpoint between (t, y) and (t + h, y + hf(t, y)). Based on this result we define the following iterative method to approximate solutions to the IVP given by eq. (3) at the mesh points given by eq. (4), , for each i = 0, 1, · · · , N -1 Here y(ti) = wi + O , and simply wi approximates of y(ti). Modified Euler method Adopting a similar approach for third order Taylor approximation we have the following iterative method of the IVP eq. (3), 2 [f(ti, wi) + f (ti+1, wi + hf(ti, wi))] , for each i = 0, 1, · · · , N -1 Here y(ti) = wi + O Order four Runge-Kutta Runge-Kutta for fourth order Taylor approximation give the following iterative method, 6(ki,1 + 2ki,2 + 2ki,3 + ki,4), for each i = 0, 1, · · · , N -1 Here y(ti) = wi + O Error bounds and computational comparison of Runge-Kutta meth- ods with Euler method The following table provides the theoretical asymptotic upper bounds for the numerical approxi- mations under each method. Method Asymptotic error bound Euler method Midpoint method Modified Euler method Fourth order Runga-Kutta The following table provides the approximations under Euler, Modified Euler and order four Runge- Kutta against the analytically computed values to the solution of the IVP Euler Modified Euler Order 4 Runge-Kutta Exact Multi-Step Methods The methods discussed in the previous section were one-step methods. Meaning that in the recursive process the (i + 1)th approximation was recursively defined based only on the ith approximation. However, in multi*- step methods the (i + 1)th approximation will be recursively defined on the previous recent approximations. As had seen in the one step methods, with increasing i accuracy of the approximations decreases. Hence, it is beneficial to factor in more accurate previous approx- imations also into the current approximation without solely relying on the approximation at the latest mesh point only. Definition 4 To approximate wi+1 an m-step multi-step method for solving the IVP, has a difference equation of the following form, + h(bmf(ti+1, wi+1) + bm-1f(ti, wi) for i = m -1, m, · · · , N -1, where h = b-a N , the a0, a1, · · · , am-1 and b0, b1, · · · , bm are constants, and the starting values are specified. The sequence of initial values α1, α2, · · · , αm-1 are usually generated using some one-step method such as Runga-Kutta or Taylor. Note that in the above definition, wi+1 may appear on both sides of the recursive equation, and hence depending on whether wi+1 appears on the right side of the equation there are two main types of multi-step methods. 1. Explicit multi-step methods: This is when bm = 0 in eq. (14). Then wi+1 is defined explicitly in terms of the previously determined values. 2. Implicit multi-step methods: This is when bm ̸= 0 in eq. (14). Then wi+1 is not defined explicitly in terms of the previously determined values, and is specified explicitly. Adam's methods The main idea behind Adam's method is the following. Consider the IVP Integrating the differential equation on the interval [ti, ti+1] we have Since y(t) is unknown, the integral of f(t, y(t)) cannot be computed. Instead we interpolate f(t, y(t)) by a polynomial P(t) based on the past m points and then integrate the polynomial. This leads to the Adam's multi-step methods. Adams-Bashforth Explicit methods For the IVP, 1. Adams-Bashforth Two-step Explicit method: where i = 1, 2, · · · , N -1. The local error is for some µ ∈(ti-1, ti+1) 2. Adams-Bashforth Three-step Explicit method: where i = 2, 3, · · · , N -1. The local error is for some µ ∈(ti-2, ti+1) 3. Adams-Bashforth Four-step Explicit method: where i = 3, 4, · · · , N -1. The local error is for some µ ∈(ti-3, ti+1) 4. Adams-Bashforth Five-step Explicit method: where i = 4, 5, · · · , N -1. The local error is for some µ ∈(ti-4, ti+1) Adams-Moulton Implicit methods For the IVP, 1. Adams-Moulton Two-step Implicit method: where i = 1, 2, · · · , N -1. The local error is for some µ ∈(ti-1, ti+1) 2. Adams-Moulton Three-step Implicit method: where i = 2, 3, · · · , N -1. The local error is for some µ ∈(ti-2, ti+1) 3. Adams-Moulton Four-step Implicit method: where i = 3, 4, · · · , N -1. The local error is for some µ ∈(ti-3, ti+1) Experimental comparison the explicit methods and implicit methods Note that the m-step Adam-Bashforth (explicit) method and the (m -1)-step Adam-Moulton (implicit) method share similar properties. Both, 1. Involve m evaluations of f per step. 2. Has error terms of the order O (hm) Hence it is worthwhile comparing the Adams-Bashforth four-step explicit method against the Adams-Moulton three-step implicit method as in the following example. Example 5 (Adams-Bashforth four-step vs Adams-Moulton three-step) Consider the IVP, Let us take h = 0.2. 1. Adam-Bashworth four-step explicit method Setting f(t, y) = y -t2 + 1 and ti = 0.2i we get, for i = 3, 4, · · · , 9. 2. Adam-Moulton three-step explicit method Setting f(t, y) = y -t2 + 1 and ti = 0.2i we get, Solving for wi+1 gives, for i = 2, 3, · · · , 9. The following table summarizes the approximations obtained from the above two methods using the exact values y(t) = (t + 1)2 -0.5et for α's. Adam-Bashworth Adam-Moulton Exact Error Error Predictor-Corrector methods In general, as had been seen in the above example implicit methods provide much better approxima- tions than implicit methods. However, using implicit methods require solving for wi+1 analytically in the recursive formulas. In general this is not possible. For example, the Adam-Moulton implicit method for following IVP, gives the recursion, 9ewi+1 + 19ewi -5ewi-1 + ewi-2\u0003 Here solving for wi+1 cannot be done analytically, so will have to resort to numerical methods which will complicate the procedure. Usually, explicit methods and implicit methods are used together in combination. Step 1 Initial approximation wi+1,p will me made by an explicit method. Step 2 wi+1,p will then be used in an implicit method to obtain an improved approximation wi+1. This is called the predictor-corrector method. Here the explicit method is called the predictor and the implicit method is called the corrector. Example 6 (Predictor-Corrector method) Consider the following IVP, with h = 0.2, Runge-Kutta as the estimator for the initial α values, the Adam-Bashforth four-step explicit method as the predictor and the Adam-Moulton three step implicit method as the corrector. The following table summarizes the approximations thus obtained. Exact Error It can be seen that this method has even better approximations than using the explicit and implicit methods separately. Numerical solutions to systems of IVPs An mth order system IVP is of the following form, for a ≤t ≤b with initial conditions u1(a) = α1, u2(a) = α2, · · · , um(a) = αm The objective is to approximate functions u1(t), u2(t), · · · , um(t) that satisfy the system eq. (22). In this section we will extend the techniques discussed earlier to a system of equations. We start with definitions and theorems analogous to those in 1st order IVPs. Definition 5 (Lipschitz functions - Higher order) The function f(t, y1, y2, · · · , ym) defined on the set, D = {(t, u1, u2, · · · , um)|a ≤t ≤b and -∞< ui < ∞} is said to satisfy Lipchitz condition on D in the variables u1, u2, · · · , um with Lipchitz constant L if a constant L > 0 exists such that, for all (t, u1, u2, · · · , um), (t, z1, z2, · · · , zm) ∈D. The following fact will help determine whether a function will satisfy a Lipchitz condition, com- putationally without appealing to the definition. Suppose the function f satisfies the following conditions, 1. f and its partial derivatives are continuous on D. for each i = 1, 2, · · · , m and all (t, u1, u2, · · · , um) ∈D then f satisfies a Lipchitz condition on D with Lipchitz constant L. Theorem 6 (Existence and uniqueness - Higher order) Suppose that D = {(t, u1, u2, · · · , um)|a ≤t ≤b and -∞< ui < ∞} and for each i = 1, 2, · · · , m let fi(t, u1, u2, · · · , um) be continuous and satisfy a Lipchitz condition on D Then the IVP define in eq. (22) has a unique solution u1(t), u2(t), · · · , um(t). Order four Runga-Kutta for IVP systems Once we have determined that there exists a unique solution to a system of IVPs, we will use a form of Runge-Kutta to approximate the solution numerically. Recall order four Runge-Kutta method eq. (25). We will introduce j as superscript to indicate the w and k approximations associated with ui(t). Order four Runge-Kutta for mth order system of IVP eq. (22) is given by the following iterative method, i,1 = hfj(ti, w(1) i,2 = hfj i,3 = hfj i,4 = hfj i,4 ), for each i = 0, 1, · · · , N -1, j = 1, 2, · · · , m Then uj(ti) ≈w(j) Here we choose an integer N > 0 and set h = b-a N . Starting with t0 = a we partition the interval [a, b] in to N subintervals with mesh points for i = 0, 1, · · · , N. Example 7 Consider the following IVP. The exact solution to this system of IVPs can derived using analytical means, The following table summarizes the apprximations and corresponding errors we get by applying order four Runga-Kutta with m = 2 for this system. Higher order IVPs We can convert an m order IVP into a m order linear system of IVPs. Consider the following m order IVP, with initial conditions We introduce new variables with the following substitutions . Hence we have the following m order systems of IVPs. with initial conditions Now order four Runga-Kutta can be used to solve this system of equations so that approximations of u1 will approximate y. Example 8 y'' -2y' + 2y = e2tsint, 0 ≤t ≤1 with Following the above process we get the following system of equations, 2 = -2u1 + 2u2 + e2tsint"
  },
  {
    "index": 7,
    "title": "Boundary Value Problems",
    "content": "MA3024 Numerical Methods Notes (BVPs) Melanka Saroad Wedige September 2024 Introduction Consider the following problem: determine y(x) such that, This is a second order differential equation with conditions asserted at the two ends y(0) = 1 and y(1) = 2. It was earlier discussed how to solve higher order ODEs by converting them into systems of 1st order ODEs. However as in all previous cases we considered, the conditions were given at a single starting point on the domain - which we called initial values problems (IVPs). This chapter will demonstrate the case in which the conditions are given on two distinct points. These problems are called boundary value problems. (BVPs) - the two conditions asserted are known as boundary conditions. The standard form of a two point boundary value problem (BVP) is as follows, In the previous examples we discussed above f(x, y, y') = xy'(x) + 2y(x) + x2, a = 0, b = 1, α = 1 and β = 2. Existence and uniquness of solutions Theorem 1 Suppose the function f in the BVP eq. (1) is continuous on the set and the partial derivatives fy, fy' are also continuous on D. In addition the following conditions are satisfied, 1. fy(x, y, y') > 0 for all (x, y, y') ∈D 2. There is a constant M > 0 such that |fy'(x, y, y')|≤M, for all (x, y, y') ∈D. Then the BVP has a uniques solution for a ≤x ≤b. Example 1 Consider the following BVP, y'' + e-xy + sin (y') = 0, 1 ≤x ≤2, y(0) = y(1) = 0 Then y'' = -e-xy -sin (y'), so f(x, y, y') = -e-xy -sin (y'). We have that fy(x, y, y') = xe-xy > 0 for all x, y. Also, fy'(x, y, y') = -cos (y') ⇒|fy'(x, y, y')|= |cos (y')|≤1 for all y'. Then by the theorem the above BVP has a unique solution. Linear Shooting Method We first consider linear boundary value problems. The standard form of a two point linear BVP is as follows, Applying theorem 1 we have the following conditions on a linear BVP for the existence and unique- ness of a solution. 1. p(x), q(x), r(x) are continuous on [a, b] 2. q(x) > 0 for x ∈[a, b] Consider the following second order IVPs, and Suppose y1(x) and y2(x) are solutions to the IVPs in eq. (3) and eq. (4) respectively. Then as a consequence of the above mentioned conditions for existence and uniqueness of solutions it can proven that y2(b) ̸= 0 whenever y2(x) is non-constant. Now let us define, It is easy to verify that this y(x) defined above is the unique solution to the BVP in eq. (1). To approximate y(x), solution to the BVP in eq. (1) is equivalent to approximating the IVPs in eq. (3) and eq. (4). To solve the IVPs we convert them into systems of linear ODEs and apply fourth order Runge-Kutta. Non-linear Shooting Method In this section we will follow a general procedure to solve non-linear BVPs. Consider the following standard form of a BVP. where f(x, y, y') is possibly a non-linear function in y and y'. We approximate the solution y(x) using a sequence of solutions y(x, tk) to a sequence of IVPs, such that lim In theory we start by solving, for some initial guess t0 as the slope of y at x = a. Suppose the solution for the above IVP is y(x, t0), and that y(b, t0) is not sufficiently close to β. Then we obtain a solution y(x, t1) for eq. (7) with y'(a) = t1, where t = t1 is another suitably chosen guess for the the slope of y at x = a. We continue the procedure until y(b, tk) is sufficiently close to β. Starting from t0 we use Newton's method to determine the sequence tk by approximating solutions to the non-linear equation in t, where y(x, t) is the solution to the IVP. Newton Iteration Starting from t = t0 to approximate solutions to y(b, t) -β = 0 we apply Newton's method as follows, However, practically y(b, tk-1) can only be obtained as a point approximation, hence determining the derivative y'(b, tk-1) analytically is not possible. Hence we use chain rule on to determine ∂y ∂t (x, t). Applying the condition ∂x ∂t = 0 and setting z(x, t) = ∂y ∂t (x, t) we have the following IVP, and initial values obtained by noting that ∂y ∂t (a, t) = 0 and ∂y' ∂t (a, t) = 1. Hence now we have, Putting all the above together we have the following algorithm for non-linear shooting method, 1. Choose an initial guess t = t0. Then repeat the following steps for k = 0, 1, 2, · · · until |y(b, tk) -β| is sufficiently small. 2. Approximate the solution yk(x) = y(x, tk) to the IVP, 3. Approximate the solution zk(x) = z(x, tk) to the IVP, 4. Update t by Newton's method, Finite-Difference Methods for Linear BVPs We consider linear BVPs in the following form, We will develop a finite difference method to approximate the solution y(x) of this BVP. Let us partition [a, b] into N + 1 equal sub-intervals of length h = N+1, of the form [xi, xi+1] for i = 0, 1, 2, · · · , N. The mesh points defined by xi = a + ih for i = 0, 1, 2, · · · , N + 1. At the interior mesh points x1, x2, · · · , xN we have the following, Using third order polynomial exapansion we have, for ξ- i ∈(xi-1, xi) and ξ+ i ∈(xi, xi+1) Adding the Taylor polynomials together we have, Applying intermediate value for y(4) there exists a ξi ∈(xi-1, xi+1) such that after simplifying we have, This is called the centered difference formula for y'''(xi). Similarly for y'(xi) we have a centered difference formula, for some ηi ∈(xi-1, xi+1) Using the centered difference formulae in eq. (11) we have, With a truncation error of O we may approximate y(xi) ≈wi recursively by the following difference formula. We may write the above system of equation in the variables wi as a matrix equation as follows, where and Hence now it is a matter of solving the matrix equation. The following theorem gives the condition under which the linear system has a uniques solution. Theorem 2 Suppose p, q, r are continuous on [a, b]. If q(x) ≥0 on [a, b] then the above system has a unique solution whenever h < 2 L, where L = max Finite-Difference Methods for Nonlinear BVPs In this section we will in brief discuss the strategy to solve nonlinear BVPs using a difference method similar to that in the linear case. We will consider the following nonlinear BVP In order to assure that a unique solution exists for the above BVP, we assume the following condi- tions, • f and the partial derivatives fy and f ' y are all continuous for all x ∈[a, b] and y, y' ∈(-∞, ∞). • fy(x, y, y') ≥δ for some δ > 0. • Constants k and L exist with k = max |fy(x, y, y'), fy'(x, y, y')| As in the linear case we consider the mesh points x0, x1, · · · , xN+1 on [a, b]. From eqs. (12) and (13) for ξi, ηi ∈(xi-1, xi+1). Hence, substituting in the BVP we have, With a truncation error of O we may approximate y(xi) ≈wi recursively by the following difference formula. for i = 1, 2, · · · , N. As a result we obtain the following N × N nonlinear system, This system will have a unique solution whenever, h < 2 L. Approximating a solution to the BVP is now reduced solving system on N-nonlinear equations with N-variables. To approximate the solution to the system of equations, Newton's method can be employed."
  },
  {
    "index": 8,
    "title": "Steepest Descent",
    "content": "MA3024 Numerical Methods Notes (Steepest Descent. Method) Melanka Saroad Wedige September 2024 Introduction We will be using a modified version of gradient descent to approximate solutions to non-linear systems of equations. As we have seen, the Newton's method has a fast convergence rate. However, Newton's method is effective only if our initial guess of a solution is sufficiently close to the actual solution, if not you may never converge to the solution or may get a pseudo solution. On the other hand the steepest descent method converges very slow to the solution, however it is much tolerant with initial guesses. Even if the initial guess is quite distant from the actual solution, the steepest descent method will eventually converge to the solution. The steepest descent is usually used to find a good enough initial guess for the Newton's method.Starting with some random initial point for steepest descent, and going through one or two iterations on the steepest descent method will give a good initial guess for Newton's method or any other faster algorithms. Setup of the problem Consider the following system of n non-linear equations with n variables. Define g : Rn →R, The minimal of g (= 0) is achieved exactly when eq. (1) is satisfied. Hence we set out goal to minimize the function g. Calculus and Gradient descent Gradient Let us write x = ∈Rn. The gradient is the 'derivative' of a multi-variable function, and will give the slope of the function in the directions of x1, x2, · · · , xn as a vector, In our situation, due to the definition g in eq. (2), we have the following formulation for the gradient Where and the Jacobian of F , Gradient descent We are currently at a point x(0) and we are planning to iteratively move towards the minimal of g. We prefer to move in the direction v∗∈Rn with the steepest slope using steps of size α > 0 at a time. Our new point will be, A result from Calculus states that the direction of steepest descent at x(0) is parallel to -∇xg(x(0)) (negative gradient of g). Hence we have the following update formula for x, for some α > 0. Steepest Descent Algorithm Next we would like to decide on the best α = ˆα, which minimizes, Performing derivatives of h and optimizing analytically is too expensive, hence we resort to an interpolation technique. For this we follow the below steps, 1. Set α1 = 0. 2. Set α = 1, now iteratively by a method of bisection find α ∈(0, 1] such that h(α3) < h(α1). 3. Define α2 = α1+α2 4. Now we define the a quadratic interpolation of the points (α1, h(α1)), (α2, h(α2)), (α3, h(α3)) where p1 = h(α1), p2 = h(α2)-h(α1) 5. We will choose as ˆα the α that minimizes P(α). Approximation of the solution to eq. (1) ≈x(0) -ˆα∇xg(x(0)) Example 1 Consider the following system of equations. f1(x1, x2, x3) = 3x1 -cos(x2x3) -1 1 -81(x2 + 0.1)2 + sinx3 + 1.06 = 0 We will start with x(0) = We have the following, 4. The unit vector in the direction of the gradient; z = In practice we use the unit vector z instead of the actual gradient g(x(0)) in the x(0)) update equation. Now to find the optimal α = ˆα that minimizes h(α) = g(x(0) -αz). 1. Start with α1 = 0 and α3 = 1. 2. We have that h(α1) = 111.975 and h(α3) = 93.5649. 3. Since h(α3) < h(α1) we accept α3 = 1. Else we continue α3 ←α3 2 until h(α3) < h(α1) or α3 is smaller than a certain tolerance, in which case we settle with that particular α3. 4. Set α2 = α1+α2 = 0.5. Then h(α2) = 2.53557. 5. To find the quadratic interpolant P(α) = p1 + p2(α -α1) + p4(α -α1)(α -α2) = p1 + p2α + p4α(α -0.5), we compute, 7. Solving P '(α0) = 0, we get α0 = 0.522959, with h(α0) = 2.32762. 8. We will choose ˆα to be the minimizer of P(α) in the interval [α1, α3]. Since h(α0) < h(α3) < h(α1), we set ˆα = α0 = 0.522959. Now and The x(1) should be good enough as an initial guess for Newton's method, however to get a better initial guess we could follow the same steps to compute x(2) starting from x(1). The following table gives the results from steepest descent upto 7 iterations. As it can be seen in the above table, the convergence of steepest descent method is quite slow, even after 7 iterations, g is very far from 0. In fact, it takes 70 iterations for x(k) to come within 0.01 distance of the actual solution."
  }
]